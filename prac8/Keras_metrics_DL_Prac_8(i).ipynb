{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras metrics DL Prac 8(i).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/payasvi/dl/blob/master/prac8/Keras_metrics_DL_Prac_8(i).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJdKMnxbQ35X",
        "colab_type": "text"
      },
      "source": [
        "#Usage of metrics\n",
        "\n",
        "A metric is a function that is used to judge the performance of your model. Metric functions are to be supplied in the metrics parameter when a model is compiled.\n",
        "\n",
        "```\n",
        "model.compile(loss='mean_squared_error',\n",
        "              optimizer='sgd',\n",
        "              metrics=['mae', 'acc'])\n",
        "from keras import metrics\n",
        "\n",
        "model.compile(loss='mean_squared_error',\n",
        "              optimizer='sgd',\n",
        "              metrics=[metrics.mae, metrics.categorical_accuracy])\n",
        "```\n",
        "\n",
        "A metric function is similar to a loss function, except that the results from evaluating a metric are not used when training the model. You may use any of the loss functions as a metric function.\n",
        "\n",
        "You can either pass the name of an existing metric, or pass a Theano/TensorFlow symbolic function (see Custom metrics).\n",
        "\n",
        "##Arguments\n",
        "1. y_true: True labels. Theano/TensorFlow tensor.\n",
        "2. y_pred: Predictions. Theano/TensorFlow tensor of the same shape as y_true.\n",
        "\n",
        "##Returns\n",
        "\n",
        "1. Single tensor value representing the mean of the output array across all datapoints."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_roXIFgkRIRf",
        "colab_type": "text"
      },
      "source": [
        "#Accuracy\n",
        "keras.metrics.accuracy(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXkjmUIiROMV",
        "colab_type": "code",
        "outputId": "4f755895-4d3a-43f2-8e94-7d368a7ced3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import keras\n",
        "from keras import models\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "\n",
        "NUM_ROWS = 28\n",
        "NUM_COLS = 28\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10\n",
        "\n",
        "# Load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Reshape data\n",
        "X_train = X_train.reshape((X_train.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.reshape((X_test.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "# Categorically encode labels\n",
        "y_train = to_categorical(y_train, NUM_CLASSES)\n",
        "y_test = to_categorical(y_test, NUM_CLASSES)\n",
        "\n",
        "\n",
        "# Build neural network\n",
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation='elu', input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation='elu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile model using accuracy\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "60000/60000 [==============================] - 11s 180us/step - loss: 0.2898 - acc: 0.9129 - val_loss: 0.1516 - val_acc: 0.9540\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.1198 - acc: 0.9633 - val_loss: 0.1325 - val_acc: 0.9583\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0826 - acc: 0.9741 - val_loss: 0.1001 - val_acc: 0.9692\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.0629 - acc: 0.9802 - val_loss: 0.0854 - val_acc: 0.9760\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.0502 - acc: 0.9839 - val_loss: 0.0795 - val_acc: 0.9757\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0402 - acc: 0.9868 - val_loss: 0.0795 - val_acc: 0.9782\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.0334 - acc: 0.9892 - val_loss: 0.0847 - val_acc: 0.9777\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0275 - acc: 0.9907 - val_loss: 0.0830 - val_acc: 0.9795\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0241 - acc: 0.9924 - val_loss: 0.0853 - val_acc: 0.9807\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0198 - acc: 0.9934 - val_loss: 0.0904 - val_acc: 0.9797\n",
            "Test loss: 0.09036049884229724\n",
            "Test accuracy: 0.9797\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTHlkI9CRX4M",
        "colab_type": "text"
      },
      "source": [
        "#binary_accuracy\n",
        "\n",
        "keras.metrics.binary_accuracy(y_true, y_pred, threshold=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yJ88okURbcn",
        "colab_type": "code",
        "outputId": "33f279cb-06e3-4849-8f32-a93ac10f04d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        }
      },
      "source": [
        "# Compile model using binary_accuracy\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['binary_accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0196 - binary_accuracy: 0.9987 - val_loss: 0.0967 - val_binary_accuracy: 0.9959\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.0145 - binary_accuracy: 0.9991 - val_loss: 0.1096 - val_binary_accuracy: 0.9957\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0131 - binary_accuracy: 0.9991 - val_loss: 0.1048 - val_binary_accuracy: 0.9960\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0119 - binary_accuracy: 0.9992 - val_loss: 0.0988 - val_binary_accuracy: 0.9962\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0109 - binary_accuracy: 0.9993 - val_loss: 0.0973 - val_binary_accuracy: 0.9962\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0091 - binary_accuracy: 0.9994 - val_loss: 0.1026 - val_binary_accuracy: 0.9965\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0088 - binary_accuracy: 0.9994 - val_loss: 0.1212 - val_binary_accuracy: 0.9960\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0091 - binary_accuracy: 0.9995 - val_loss: 0.1159 - val_binary_accuracy: 0.9960\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0074 - binary_accuracy: 0.9995 - val_loss: 0.1260 - val_binary_accuracy: 0.9960\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0073 - binary_accuracy: 0.9995 - val_loss: 0.1286 - val_binary_accuracy: 0.9961\n",
            "Test loss: 0.12862838905762616\n",
            "Test accuracy: 0.9960599964141845\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i34lhk62Rr00",
        "colab_type": "text"
      },
      "source": [
        "#categorical_accuracy\n",
        "\n",
        "keras.metrics.categorical_accuracy(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8yiFITLRut3",
        "colab_type": "code",
        "outputId": "5af4ce65-6c62-42fa-a3ac-401b158835c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        }
      },
      "source": [
        "# Compile model using categorical_accuracy\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['categorical_accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0068 - categorical_accuracy: 0.9979 - val_loss: 0.1126 - val_categorical_accuracy: 0.9820\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.0066 - categorical_accuracy: 0.9979 - val_loss: 0.1380 - val_categorical_accuracy: 0.9790\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 0.0056 - categorical_accuracy: 0.9982 - val_loss: 0.1105 - val_categorical_accuracy: 0.9828\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0060 - categorical_accuracy: 0.9984 - val_loss: 0.1232 - val_categorical_accuracy: 0.9817\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0059 - categorical_accuracy: 0.9982 - val_loss: 0.1277 - val_categorical_accuracy: 0.9812\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0068 - categorical_accuracy: 0.9982 - val_loss: 0.1208 - val_categorical_accuracy: 0.9820\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 0.0047 - categorical_accuracy: 0.9986 - val_loss: 0.1167 - val_categorical_accuracy: 0.9827\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0037 - categorical_accuracy: 0.9990 - val_loss: 0.1377 - val_categorical_accuracy: 0.9827\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 0.0036 - categorical_accuracy: 0.9990 - val_loss: 0.1324 - val_categorical_accuracy: 0.9804\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0047 - categorical_accuracy: 0.9987 - val_loss: 0.1391 - val_categorical_accuracy: 0.9814\n",
            "Test loss: 0.13909786675752067\n",
            "Test accuracy: 0.9814\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2C271EXSqnV",
        "colab_type": "text"
      },
      "source": [
        "#top_k_categorical_accuracy\n",
        "\n",
        "keras.metrics.top_k_categorical_accuracy(y_true, y_pred, k=5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70hdQEGZSsKM",
        "colab_type": "code",
        "outputId": "3426881e-ad03-4820-b1fc-36951096dfff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        }
      },
      "source": [
        "# Compile model using categorical_accuracy\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['top_k_categorical_accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0045 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1342 - val_top_k_categorical_accuracy: 0.9998\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 0.0036 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1332 - val_top_k_categorical_accuracy: 0.9997\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 0.0037 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1443 - val_top_k_categorical_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.0045 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1574 - val_top_k_categorical_accuracy: 0.9998\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0047 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1556 - val_top_k_categorical_accuracy: 0.9999\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0035 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1478 - val_top_k_categorical_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0039 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1526 - val_top_k_categorical_accuracy: 0.9997\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0035 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1548 - val_top_k_categorical_accuracy: 0.9999\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0033 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1523 - val_top_k_categorical_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 0.0032 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1608 - val_top_k_categorical_accuracy: 0.9999\n",
            "Test loss: 0.16084585186516762\n",
            "Test accuracy: 0.9999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WTKc7LCR22d",
        "colab_type": "text"
      },
      "source": [
        "#sparse_categorical_accuracy\n",
        "\n",
        "keras.metrics.sparse_categorical_accuracy(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpEKVQaQR-iq",
        "colab_type": "code",
        "outputId": "ca4fca30-f547-4423-a7aa-c1ffefa41771",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from matplotlib import pyplot\n",
        "# prepare sequence\n",
        "X = array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
        "y = array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(2, input_dim=1))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['sparse_categorical_accuracy'])\n",
        "# train model\n",
        "history = model.fit(X, y, epochs=400, batch_size=len(X), verbose=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            " - 0s - loss: 0.7885 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 2/400\n",
            " - 0s - loss: 0.7879 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 3/400\n",
            " - 0s - loss: 0.7874 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 4/400\n",
            " - 0s - loss: 0.7868 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 5/400\n",
            " - 0s - loss: 0.7862 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 6/400\n",
            " - 0s - loss: 0.7856 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 7/400\n",
            " - 0s - loss: 0.7851 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 8/400\n",
            " - 0s - loss: 0.7845 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 9/400\n",
            " - 0s - loss: 0.7840 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 10/400\n",
            " - 0s - loss: 0.7834 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 11/400\n",
            " - 0s - loss: 0.7829 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 12/400\n",
            " - 0s - loss: 0.7823 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 13/400\n",
            " - 0s - loss: 0.7818 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 14/400\n",
            " - 0s - loss: 0.7813 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 15/400\n",
            " - 0s - loss: 0.7807 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 16/400\n",
            " - 0s - loss: 0.7802 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 17/400\n",
            " - 0s - loss: 0.7797 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 18/400\n",
            " - 0s - loss: 0.7792 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 19/400\n",
            " - 0s - loss: 0.7787 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 20/400\n",
            " - 0s - loss: 0.7781 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 21/400\n",
            " - 0s - loss: 0.7776 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 22/400\n",
            " - 0s - loss: 0.7771 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 23/400\n",
            " - 0s - loss: 0.7767 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 24/400\n",
            " - 0s - loss: 0.7762 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 25/400\n",
            " - 0s - loss: 0.7757 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 26/400\n",
            " - 0s - loss: 0.7752 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 27/400\n",
            " - 0s - loss: 0.7747 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 28/400\n",
            " - 0s - loss: 0.7742 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 29/400\n",
            " - 0s - loss: 0.7738 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 30/400\n",
            " - 0s - loss: 0.7733 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 31/400\n",
            " - 0s - loss: 0.7729 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 32/400\n",
            " - 0s - loss: 0.7724 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 33/400\n",
            " - 0s - loss: 0.7720 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 34/400\n",
            " - 0s - loss: 0.7715 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 35/400\n",
            " - 0s - loss: 0.7711 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 36/400\n",
            " - 0s - loss: 0.7706 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 37/400\n",
            " - 0s - loss: 0.7702 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 38/400\n",
            " - 0s - loss: 0.7698 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 39/400\n",
            " - 0s - loss: 0.7693 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 40/400\n",
            " - 0s - loss: 0.7689 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 41/400\n",
            " - 0s - loss: 0.7685 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 42/400\n",
            " - 0s - loss: 0.7681 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 43/400\n",
            " - 0s - loss: 0.7677 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 44/400\n",
            " - 0s - loss: 0.7673 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 45/400\n",
            " - 0s - loss: 0.7669 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 46/400\n",
            " - 0s - loss: 0.7665 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 47/400\n",
            " - 0s - loss: 0.7661 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 48/400\n",
            " - 0s - loss: 0.7657 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 49/400\n",
            " - 0s - loss: 0.7653 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 50/400\n",
            " - 0s - loss: 0.7649 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 51/400\n",
            " - 0s - loss: 0.7646 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 52/400\n",
            " - 0s - loss: 0.7642 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 53/400\n",
            " - 0s - loss: 0.7638 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 54/400\n",
            " - 0s - loss: 0.7634 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 55/400\n",
            " - 0s - loss: 0.7631 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 56/400\n",
            " - 0s - loss: 0.7627 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 57/400\n",
            " - 0s - loss: 0.7624 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 58/400\n",
            " - 0s - loss: 0.7620 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 59/400\n",
            " - 0s - loss: 0.7617 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 60/400\n",
            " - 0s - loss: 0.7613 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 61/400\n",
            " - 0s - loss: 0.7610 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 62/400\n",
            " - 0s - loss: 0.7606 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 63/400\n",
            " - 0s - loss: 0.7603 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 64/400\n",
            " - 0s - loss: 0.7600 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 65/400\n",
            " - 0s - loss: 0.7596 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 66/400\n",
            " - 0s - loss: 0.7593 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 67/400\n",
            " - 0s - loss: 0.7590 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 68/400\n",
            " - 0s - loss: 0.7587 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 69/400\n",
            " - 0s - loss: 0.7583 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 70/400\n",
            " - 0s - loss: 0.7580 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 71/400\n",
            " - 0s - loss: 0.7577 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 72/400\n",
            " - 0s - loss: 0.7574 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 73/400\n",
            " - 0s - loss: 0.7571 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 74/400\n",
            " - 0s - loss: 0.7568 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 75/400\n",
            " - 0s - loss: 0.7565 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 76/400\n",
            " - 0s - loss: 0.7562 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 77/400\n",
            " - 0s - loss: 0.7559 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 78/400\n",
            " - 0s - loss: 0.7556 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 79/400\n",
            " - 0s - loss: 0.7553 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 80/400\n",
            " - 0s - loss: 0.7550 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 81/400\n",
            " - 0s - loss: 0.7547 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 82/400\n",
            " - 0s - loss: 0.7544 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 83/400\n",
            " - 0s - loss: 0.7542 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 84/400\n",
            " - 0s - loss: 0.7539 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 85/400\n",
            " - 0s - loss: 0.7536 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 86/400\n",
            " - 0s - loss: 0.7533 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 87/400\n",
            " - 0s - loss: 0.7531 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 88/400\n",
            " - 0s - loss: 0.7528 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 89/400\n",
            " - 0s - loss: 0.7525 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 90/400\n",
            " - 0s - loss: 0.7523 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 91/400\n",
            " - 0s - loss: 0.7520 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 92/400\n",
            " - 0s - loss: 0.7517 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 93/400\n",
            " - 0s - loss: 0.7515 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 94/400\n",
            " - 0s - loss: 0.7512 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 95/400\n",
            " - 0s - loss: 0.7510 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 96/400\n",
            " - 0s - loss: 0.7507 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 97/400\n",
            " - 0s - loss: 0.7505 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 98/400\n",
            " - 0s - loss: 0.7502 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 99/400\n",
            " - 0s - loss: 0.7500 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 100/400\n",
            " - 0s - loss: 0.7497 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 101/400\n",
            " - 0s - loss: 0.7495 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 102/400\n",
            " - 0s - loss: 0.7492 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 103/400\n",
            " - 0s - loss: 0.7490 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 104/400\n",
            " - 0s - loss: 0.7487 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 105/400\n",
            " - 0s - loss: 0.7485 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 106/400\n",
            " - 0s - loss: 0.7483 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 107/400\n",
            " - 0s - loss: 0.7480 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 108/400\n",
            " - 0s - loss: 0.7478 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 109/400\n",
            " - 0s - loss: 0.7476 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 110/400\n",
            " - 0s - loss: 0.7473 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 111/400\n",
            " - 0s - loss: 0.7471 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 112/400\n",
            " - 0s - loss: 0.7469 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 113/400\n",
            " - 0s - loss: 0.7467 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 114/400\n",
            " - 0s - loss: 0.7464 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 115/400\n",
            " - 0s - loss: 0.7462 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 116/400\n",
            " - 0s - loss: 0.7460 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 117/400\n",
            " - 0s - loss: 0.7458 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 118/400\n",
            " - 0s - loss: 0.7456 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 119/400\n",
            " - 0s - loss: 0.7454 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 120/400\n",
            " - 0s - loss: 0.7451 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 121/400\n",
            " - 0s - loss: 0.7449 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 122/400\n",
            " - 0s - loss: 0.7447 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 123/400\n",
            " - 0s - loss: 0.7445 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 124/400\n",
            " - 0s - loss: 0.7443 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 125/400\n",
            " - 0s - loss: 0.7441 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 126/400\n",
            " - 0s - loss: 0.7439 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 127/400\n",
            " - 0s - loss: 0.7437 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 128/400\n",
            " - 0s - loss: 0.7435 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 129/400\n",
            " - 0s - loss: 0.7433 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 130/400\n",
            " - 0s - loss: 0.7431 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 131/400\n",
            " - 0s - loss: 0.7429 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 132/400\n",
            " - 0s - loss: 0.7427 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 133/400\n",
            " - 0s - loss: 0.7425 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 134/400\n",
            " - 0s - loss: 0.7423 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 135/400\n",
            " - 0s - loss: 0.7421 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 136/400\n",
            " - 0s - loss: 0.7419 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 137/400\n",
            " - 0s - loss: 0.7417 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 138/400\n",
            " - 0s - loss: 0.7415 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 139/400\n",
            " - 0s - loss: 0.7413 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 140/400\n",
            " - 0s - loss: 0.7411 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 141/400\n",
            " - 0s - loss: 0.7409 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 142/400\n",
            " - 0s - loss: 0.7407 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 143/400\n",
            " - 0s - loss: 0.7406 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 144/400\n",
            " - 0s - loss: 0.7404 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 145/400\n",
            " - 0s - loss: 0.7402 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 146/400\n",
            " - 0s - loss: 0.7400 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 147/400\n",
            " - 0s - loss: 0.7398 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 148/400\n",
            " - 0s - loss: 0.7396 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 149/400\n",
            " - 0s - loss: 0.7394 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 150/400\n",
            " - 0s - loss: 0.7393 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 151/400\n",
            " - 0s - loss: 0.7391 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 152/400\n",
            " - 0s - loss: 0.7389 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 153/400\n",
            " - 0s - loss: 0.7387 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 154/400\n",
            " - 0s - loss: 0.7385 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 155/400\n",
            " - 0s - loss: 0.7384 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 156/400\n",
            " - 0s - loss: 0.7382 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 157/400\n",
            " - 0s - loss: 0.7380 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 158/400\n",
            " - 0s - loss: 0.7378 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 159/400\n",
            " - 0s - loss: 0.7377 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 160/400\n",
            " - 0s - loss: 0.7375 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 161/400\n",
            " - 0s - loss: 0.7373 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 162/400\n",
            " - 0s - loss: 0.7371 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 163/400\n",
            " - 0s - loss: 0.7370 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 164/400\n",
            " - 0s - loss: 0.7368 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 165/400\n",
            " - 0s - loss: 0.7366 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 166/400\n",
            " - 0s - loss: 0.7365 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 167/400\n",
            " - 0s - loss: 0.7363 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 168/400\n",
            " - 0s - loss: 0.7361 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 169/400\n",
            " - 0s - loss: 0.7360 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 170/400\n",
            " - 0s - loss: 0.7358 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 171/400\n",
            " - 0s - loss: 0.7356 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 172/400\n",
            " - 0s - loss: 0.7355 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 173/400\n",
            " - 0s - loss: 0.7353 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 174/400\n",
            " - 0s - loss: 0.7351 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 175/400\n",
            " - 0s - loss: 0.7350 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 176/400\n",
            " - 0s - loss: 0.7348 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 177/400\n",
            " - 0s - loss: 0.7347 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 178/400\n",
            " - 0s - loss: 0.7345 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 179/400\n",
            " - 0s - loss: 0.7343 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 180/400\n",
            " - 0s - loss: 0.7342 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 181/400\n",
            " - 0s - loss: 0.7340 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 182/400\n",
            " - 0s - loss: 0.7339 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 183/400\n",
            " - 0s - loss: 0.7337 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 184/400\n",
            " - 0s - loss: 0.7335 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 185/400\n",
            " - 0s - loss: 0.7334 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 186/400\n",
            " - 0s - loss: 0.7332 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 187/400\n",
            " - 0s - loss: 0.7331 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 188/400\n",
            " - 0s - loss: 0.7329 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 189/400\n",
            " - 0s - loss: 0.7328 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 190/400\n",
            " - 0s - loss: 0.7326 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 191/400\n",
            " - 0s - loss: 0.7325 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 192/400\n",
            " - 0s - loss: 0.7323 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 193/400\n",
            " - 0s - loss: 0.7321 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 194/400\n",
            " - 0s - loss: 0.7320 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 195/400\n",
            " - 0s - loss: 0.7318 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 196/400\n",
            " - 0s - loss: 0.7317 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 197/400\n",
            " - 0s - loss: 0.7315 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 198/400\n",
            " - 0s - loss: 0.7314 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 199/400\n",
            " - 0s - loss: 0.7312 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 200/400\n",
            " - 0s - loss: 0.7311 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 201/400\n",
            " - 0s - loss: 0.7309 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 202/400\n",
            " - 0s - loss: 0.7308 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 203/400\n",
            " - 0s - loss: 0.7306 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 204/400\n",
            " - 0s - loss: 0.7305 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 205/400\n",
            " - 0s - loss: 0.7303 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 206/400\n",
            " - 0s - loss: 0.7302 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 207/400\n",
            " - 0s - loss: 0.7301 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 208/400\n",
            " - 0s - loss: 0.7299 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 209/400\n",
            " - 0s - loss: 0.7298 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 210/400\n",
            " - 0s - loss: 0.7296 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 211/400\n",
            " - 0s - loss: 0.7295 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 212/400\n",
            " - 0s - loss: 0.7293 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 213/400\n",
            " - 0s - loss: 0.7292 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 214/400\n",
            " - 0s - loss: 0.7290 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 215/400\n",
            " - 0s - loss: 0.7289 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 216/400\n",
            " - 0s - loss: 0.7288 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 217/400\n",
            " - 0s - loss: 0.7286 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 218/400\n",
            " - 0s - loss: 0.7285 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 219/400\n",
            " - 0s - loss: 0.7283 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 220/400\n",
            " - 0s - loss: 0.7282 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 221/400\n",
            " - 0s - loss: 0.7281 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 222/400\n",
            " - 0s - loss: 0.7279 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 223/400\n",
            " - 0s - loss: 0.7278 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 224/400\n",
            " - 0s - loss: 0.7276 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 225/400\n",
            " - 0s - loss: 0.7275 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 226/400\n",
            " - 0s - loss: 0.7274 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 227/400\n",
            " - 0s - loss: 0.7272 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 228/400\n",
            " - 0s - loss: 0.7271 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 229/400\n",
            " - 0s - loss: 0.7270 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 230/400\n",
            " - 0s - loss: 0.7268 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 231/400\n",
            " - 0s - loss: 0.7267 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 232/400\n",
            " - 0s - loss: 0.7265 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 233/400\n",
            " - 0s - loss: 0.7264 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 234/400\n",
            " - 0s - loss: 0.7263 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 235/400\n",
            " - 0s - loss: 0.7261 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 236/400\n",
            " - 0s - loss: 0.7260 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 237/400\n",
            " - 0s - loss: 0.7259 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 238/400\n",
            " - 0s - loss: 0.7257 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 239/400\n",
            " - 0s - loss: 0.7256 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 240/400\n",
            " - 0s - loss: 0.7255 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 241/400\n",
            " - 0s - loss: 0.7253 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 242/400\n",
            " - 0s - loss: 0.7252 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 243/400\n",
            " - 0s - loss: 0.7251 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 244/400\n",
            " - 0s - loss: 0.7250 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 245/400\n",
            " - 0s - loss: 0.7248 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 246/400\n",
            " - 0s - loss: 0.7247 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 247/400\n",
            " - 0s - loss: 0.7246 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 248/400\n",
            " - 0s - loss: 0.7244 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 249/400\n",
            " - 0s - loss: 0.7243 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 250/400\n",
            " - 0s - loss: 0.7242 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 251/400\n",
            " - 0s - loss: 0.7240 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 252/400\n",
            " - 0s - loss: 0.7239 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 253/400\n",
            " - 0s - loss: 0.7238 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 254/400\n",
            " - 0s - loss: 0.7237 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 255/400\n",
            " - 0s - loss: 0.7235 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 256/400\n",
            " - 0s - loss: 0.7234 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 257/400\n",
            " - 0s - loss: 0.7233 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 258/400\n",
            " - 0s - loss: 0.7232 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 259/400\n",
            " - 0s - loss: 0.7230 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 260/400\n",
            " - 0s - loss: 0.7229 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 261/400\n",
            " - 0s - loss: 0.7228 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 262/400\n",
            " - 0s - loss: 0.7227 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 263/400\n",
            " - 0s - loss: 0.7225 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 264/400\n",
            " - 0s - loss: 0.7224 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 265/400\n",
            " - 0s - loss: 0.7223 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 266/400\n",
            " - 0s - loss: 0.7222 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 267/400\n",
            " - 0s - loss: 0.7220 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 268/400\n",
            " - 0s - loss: 0.7219 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 269/400\n",
            " - 0s - loss: 0.7218 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 270/400\n",
            " - 0s - loss: 0.7217 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 271/400\n",
            " - 0s - loss: 0.7216 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 272/400\n",
            " - 0s - loss: 0.7214 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 273/400\n",
            " - 0s - loss: 0.7213 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 274/400\n",
            " - 0s - loss: 0.7212 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 275/400\n",
            " - 0s - loss: 0.7211 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 276/400\n",
            " - 0s - loss: 0.7210 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 277/400\n",
            " - 0s - loss: 0.7208 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 278/400\n",
            " - 0s - loss: 0.7207 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 279/400\n",
            " - 0s - loss: 0.7206 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 280/400\n",
            " - 0s - loss: 0.7205 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 281/400\n",
            " - 0s - loss: 0.7204 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 282/400\n",
            " - 0s - loss: 0.7202 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 283/400\n",
            " - 0s - loss: 0.7201 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 284/400\n",
            " - 0s - loss: 0.7200 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 285/400\n",
            " - 0s - loss: 0.7199 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 286/400\n",
            " - 0s - loss: 0.7198 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 287/400\n",
            " - 0s - loss: 0.7197 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 288/400\n",
            " - 0s - loss: 0.7195 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 289/400\n",
            " - 0s - loss: 0.7194 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 290/400\n",
            " - 0s - loss: 0.7193 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 291/400\n",
            " - 0s - loss: 0.7192 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 292/400\n",
            " - 0s - loss: 0.7191 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 293/400\n",
            " - 0s - loss: 0.7190 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 294/400\n",
            " - 0s - loss: 0.7189 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 295/400\n",
            " - 0s - loss: 0.7187 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 296/400\n",
            " - 0s - loss: 0.7186 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 297/400\n",
            " - 0s - loss: 0.7185 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 298/400\n",
            " - 0s - loss: 0.7184 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 299/400\n",
            " - 0s - loss: 0.7183 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 300/400\n",
            " - 0s - loss: 0.7182 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 301/400\n",
            " - 0s - loss: 0.7181 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 302/400\n",
            " - 0s - loss: 0.7180 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 303/400\n",
            " - 0s - loss: 0.7178 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 304/400\n",
            " - 0s - loss: 0.7177 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 305/400\n",
            " - 0s - loss: 0.7176 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 306/400\n",
            " - 0s - loss: 0.7175 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 307/400\n",
            " - 0s - loss: 0.7174 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 308/400\n",
            " - 0s - loss: 0.7173 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 309/400\n",
            " - 0s - loss: 0.7172 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 310/400\n",
            " - 0s - loss: 0.7171 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 311/400\n",
            " - 0s - loss: 0.7170 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 312/400\n",
            " - 0s - loss: 0.7169 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 313/400\n",
            " - 0s - loss: 0.7167 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 314/400\n",
            " - 0s - loss: 0.7166 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 315/400\n",
            " - 0s - loss: 0.7165 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 316/400\n",
            " - 0s - loss: 0.7164 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 317/400\n",
            " - 0s - loss: 0.7163 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 318/400\n",
            " - 0s - loss: 0.7162 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 319/400\n",
            " - 0s - loss: 0.7161 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 320/400\n",
            " - 0s - loss: 0.7160 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 321/400\n",
            " - 0s - loss: 0.7159 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 322/400\n",
            " - 0s - loss: 0.7158 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 323/400\n",
            " - 0s - loss: 0.7157 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 324/400\n",
            " - 0s - loss: 0.7156 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 325/400\n",
            " - 0s - loss: 0.7155 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 326/400\n",
            " - 0s - loss: 0.7154 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 327/400\n",
            " - 0s - loss: 0.7153 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 328/400\n",
            " - 0s - loss: 0.7152 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 329/400\n",
            " - 0s - loss: 0.7151 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 330/400\n",
            " - 0s - loss: 0.7149 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 331/400\n",
            " - 0s - loss: 0.7148 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 332/400\n",
            " - 0s - loss: 0.7147 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 333/400\n",
            " - 0s - loss: 0.7146 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 334/400\n",
            " - 0s - loss: 0.7145 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 335/400\n",
            " - 0s - loss: 0.7144 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 336/400\n",
            " - 0s - loss: 0.7143 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 337/400\n",
            " - 0s - loss: 0.7142 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 338/400\n",
            " - 0s - loss: 0.7141 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 339/400\n",
            " - 0s - loss: 0.7140 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 340/400\n",
            " - 0s - loss: 0.7139 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 341/400\n",
            " - 0s - loss: 0.7138 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 342/400\n",
            " - 0s - loss: 0.7137 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 343/400\n",
            " - 0s - loss: 0.7136 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 344/400\n",
            " - 0s - loss: 0.7135 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 345/400\n",
            " - 0s - loss: 0.7134 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 346/400\n",
            " - 0s - loss: 0.7133 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 347/400\n",
            " - 0s - loss: 0.7132 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 348/400\n",
            " - 0s - loss: 0.7131 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 349/400\n",
            " - 0s - loss: 0.7130 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 350/400\n",
            " - 0s - loss: 0.7129 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 351/400\n",
            " - 0s - loss: 0.7128 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 352/400\n",
            " - 0s - loss: 0.7127 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 353/400\n",
            " - 0s - loss: 0.7126 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 354/400\n",
            " - 0s - loss: 0.7126 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 355/400\n",
            " - 0s - loss: 0.7125 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 356/400\n",
            " - 0s - loss: 0.7124 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 357/400\n",
            " - 0s - loss: 0.7123 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 358/400\n",
            " - 0s - loss: 0.7122 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 359/400\n",
            " - 0s - loss: 0.7121 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 360/400\n",
            " - 0s - loss: 0.7120 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 361/400\n",
            " - 0s - loss: 0.7119 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 362/400\n",
            " - 0s - loss: 0.7118 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 363/400\n",
            " - 0s - loss: 0.7117 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 364/400\n",
            " - 0s - loss: 0.7116 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 365/400\n",
            " - 0s - loss: 0.7115 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 366/400\n",
            " - 0s - loss: 0.7114 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 367/400\n",
            " - 0s - loss: 0.7113 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 368/400\n",
            " - 0s - loss: 0.7112 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 369/400\n",
            " - 0s - loss: 0.7111 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 370/400\n",
            " - 0s - loss: 0.7110 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 371/400\n",
            " - 0s - loss: 0.7109 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 372/400\n",
            " - 0s - loss: 0.7109 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 373/400\n",
            " - 0s - loss: 0.7108 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 374/400\n",
            " - 0s - loss: 0.7107 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 375/400\n",
            " - 0s - loss: 0.7106 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 376/400\n",
            " - 0s - loss: 0.7105 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 377/400\n",
            " - 0s - loss: 0.7104 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 378/400\n",
            " - 0s - loss: 0.7103 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 379/400\n",
            " - 0s - loss: 0.7102 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 380/400\n",
            " - 0s - loss: 0.7101 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 381/400\n",
            " - 0s - loss: 0.7100 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 382/400\n",
            " - 0s - loss: 0.7099 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 383/400\n",
            " - 0s - loss: 0.7099 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 384/400\n",
            " - 0s - loss: 0.7098 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 385/400\n",
            " - 0s - loss: 0.7097 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 386/400\n",
            " - 0s - loss: 0.7096 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 387/400\n",
            " - 0s - loss: 0.7095 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 388/400\n",
            " - 0s - loss: 0.7094 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 389/400\n",
            " - 0s - loss: 0.7093 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 390/400\n",
            " - 0s - loss: 0.7092 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 391/400\n",
            " - 0s - loss: 0.7091 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 392/400\n",
            " - 0s - loss: 0.7091 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 393/400\n",
            " - 0s - loss: 0.7090 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 394/400\n",
            " - 0s - loss: 0.7089 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 395/400\n",
            " - 0s - loss: 0.7088 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 396/400\n",
            " - 0s - loss: 0.7087 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 397/400\n",
            " - 0s - loss: 0.7086 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 398/400\n",
            " - 0s - loss: 0.7085 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 399/400\n",
            " - 0s - loss: 0.7084 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 400/400\n",
            " - 0s - loss: 0.7084 - sparse_categorical_accuracy: 0.5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHCFoRZKUdki",
        "colab_type": "text"
      },
      "source": [
        "#sparse_top_k_categorical_accuracy\n",
        "\n",
        "keras.metrics.sparse_top_k_categorical_accuracy(y_true, y_pred, k=5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8FWdLp_UfPi",
        "colab_type": "code",
        "outputId": "8ee00f6e-e83f-4b2d-9079-e21094a7fb01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from matplotlib import pyplot\n",
        "# prepare sequence\n",
        "X = array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
        "y = array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(2, input_dim=1))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['sparse_top_k_categorical_accuracy'])\n",
        "# train model\n",
        "history = model.fit(X, y, epochs=400, batch_size=len(X), verbose=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            " - 0s - loss: 0.7121 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 2/400\n",
            " - 0s - loss: 0.7118 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 3/400\n",
            " - 0s - loss: 0.7115 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 4/400\n",
            " - 0s - loss: 0.7111 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 5/400\n",
            " - 0s - loss: 0.7107 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 6/400\n",
            " - 0s - loss: 0.7103 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 7/400\n",
            " - 0s - loss: 0.7099 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 8/400\n",
            " - 0s - loss: 0.7096 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 9/400\n",
            " - 0s - loss: 0.7092 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 10/400\n",
            " - 0s - loss: 0.7088 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 11/400\n",
            " - 0s - loss: 0.7084 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 12/400\n",
            " - 0s - loss: 0.7080 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 13/400\n",
            " - 0s - loss: 0.7076 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 14/400\n",
            " - 0s - loss: 0.7072 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 15/400\n",
            " - 0s - loss: 0.7069 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 16/400\n",
            " - 0s - loss: 0.7065 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 17/400\n",
            " - 0s - loss: 0.7061 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 18/400\n",
            " - 0s - loss: 0.7057 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 19/400\n",
            " - 0s - loss: 0.7053 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 20/400\n",
            " - 0s - loss: 0.7050 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 21/400\n",
            " - 0s - loss: 0.7046 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 22/400\n",
            " - 0s - loss: 0.7042 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 23/400\n",
            " - 0s - loss: 0.7039 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 24/400\n",
            " - 0s - loss: 0.7035 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 25/400\n",
            " - 0s - loss: 0.7032 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 26/400\n",
            " - 0s - loss: 0.7028 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 27/400\n",
            " - 0s - loss: 0.7024 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 28/400\n",
            " - 0s - loss: 0.7021 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 29/400\n",
            " - 0s - loss: 0.7017 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 30/400\n",
            " - 0s - loss: 0.7014 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 31/400\n",
            " - 0s - loss: 0.7010 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 32/400\n",
            " - 0s - loss: 0.7007 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 33/400\n",
            " - 0s - loss: 0.7004 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 34/400\n",
            " - 0s - loss: 0.7000 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 35/400\n",
            " - 0s - loss: 0.6997 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 36/400\n",
            " - 0s - loss: 0.6993 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 37/400\n",
            " - 0s - loss: 0.6990 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 38/400\n",
            " - 0s - loss: 0.6987 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 39/400\n",
            " - 0s - loss: 0.6983 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 40/400\n",
            " - 0s - loss: 0.6980 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 41/400\n",
            " - 0s - loss: 0.6977 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 42/400\n",
            " - 0s - loss: 0.6973 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 43/400\n",
            " - 0s - loss: 0.6970 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 44/400\n",
            " - 0s - loss: 0.6967 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 45/400\n",
            " - 0s - loss: 0.6963 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 46/400\n",
            " - 0s - loss: 0.6960 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 47/400\n",
            " - 0s - loss: 0.6957 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 48/400\n",
            " - 0s - loss: 0.6953 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 49/400\n",
            " - 0s - loss: 0.6950 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 50/400\n",
            " - 0s - loss: 0.6947 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 51/400\n",
            " - 0s - loss: 0.6943 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 52/400\n",
            " - 0s - loss: 0.6940 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 53/400\n",
            " - 0s - loss: 0.6937 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 54/400\n",
            " - 0s - loss: 0.6934 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 55/400\n",
            " - 0s - loss: 0.6930 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 56/400\n",
            " - 0s - loss: 0.6927 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 57/400\n",
            " - 0s - loss: 0.6924 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 58/400\n",
            " - 0s - loss: 0.6920 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 59/400\n",
            " - 0s - loss: 0.6917 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 60/400\n",
            " - 0s - loss: 0.6914 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 61/400\n",
            " - 0s - loss: 0.6911 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 62/400\n",
            " - 0s - loss: 0.6907 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 63/400\n",
            " - 0s - loss: 0.6904 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 64/400\n",
            " - 0s - loss: 0.6901 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 65/400\n",
            " - 0s - loss: 0.6897 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 66/400\n",
            " - 0s - loss: 0.6894 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 67/400\n",
            " - 0s - loss: 0.6891 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 68/400\n",
            " - 0s - loss: 0.6888 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 69/400\n",
            " - 0s - loss: 0.6884 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 70/400\n",
            " - 0s - loss: 0.6881 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 71/400\n",
            " - 0s - loss: 0.6878 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 72/400\n",
            " - 0s - loss: 0.6874 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 73/400\n",
            " - 0s - loss: 0.6871 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 74/400\n",
            " - 0s - loss: 0.6868 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 75/400\n",
            " - 0s - loss: 0.6865 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 76/400\n",
            " - 0s - loss: 0.6861 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 77/400\n",
            " - 0s - loss: 0.6858 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 78/400\n",
            " - 0s - loss: 0.6855 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 79/400\n",
            " - 0s - loss: 0.6851 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 80/400\n",
            " - 0s - loss: 0.6848 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 81/400\n",
            " - 0s - loss: 0.6845 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 82/400\n",
            " - 0s - loss: 0.6841 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 83/400\n",
            " - 0s - loss: 0.6838 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 84/400\n",
            " - 0s - loss: 0.6835 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 85/400\n",
            " - 0s - loss: 0.6832 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 86/400\n",
            " - 0s - loss: 0.6828 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 87/400\n",
            " - 0s - loss: 0.6825 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 88/400\n",
            " - 0s - loss: 0.6822 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 89/400\n",
            " - 0s - loss: 0.6818 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 90/400\n",
            " - 0s - loss: 0.6815 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 91/400\n",
            " - 0s - loss: 0.6812 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 92/400\n",
            " - 0s - loss: 0.6809 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 93/400\n",
            " - 0s - loss: 0.6805 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 94/400\n",
            " - 0s - loss: 0.6802 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 95/400\n",
            " - 0s - loss: 0.6799 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 96/400\n",
            " - 0s - loss: 0.6795 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 97/400\n",
            " - 0s - loss: 0.6792 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 98/400\n",
            " - 0s - loss: 0.6789 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 99/400\n",
            " - 0s - loss: 0.6786 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 100/400\n",
            " - 0s - loss: 0.6782 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 101/400\n",
            " - 0s - loss: 0.6779 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 102/400\n",
            " - 0s - loss: 0.6776 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 103/400\n",
            " - 0s - loss: 0.6772 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 104/400\n",
            " - 0s - loss: 0.6769 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 105/400\n",
            " - 0s - loss: 0.6766 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 106/400\n",
            " - 0s - loss: 0.6762 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 107/400\n",
            " - 0s - loss: 0.6759 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 108/400\n",
            " - 0s - loss: 0.6756 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 109/400\n",
            " - 0s - loss: 0.6753 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 110/400\n",
            " - 0s - loss: 0.6749 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 111/400\n",
            " - 0s - loss: 0.6746 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 112/400\n",
            " - 0s - loss: 0.6743 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 113/400\n",
            " - 0s - loss: 0.6739 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 114/400\n",
            " - 0s - loss: 0.6736 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 115/400\n",
            " - 0s - loss: 0.6733 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 116/400\n",
            " - 0s - loss: 0.6730 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 117/400\n",
            " - 0s - loss: 0.6726 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 118/400\n",
            " - 0s - loss: 0.6723 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 119/400\n",
            " - 0s - loss: 0.6720 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 120/400\n",
            " - 0s - loss: 0.6716 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 121/400\n",
            " - 0s - loss: 0.6713 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 122/400\n",
            " - 0s - loss: 0.6710 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 123/400\n",
            " - 0s - loss: 0.6706 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 124/400\n",
            " - 0s - loss: 0.6703 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 125/400\n",
            " - 0s - loss: 0.6700 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 126/400\n",
            " - 0s - loss: 0.6697 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 127/400\n",
            " - 0s - loss: 0.6693 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 128/400\n",
            " - 0s - loss: 0.6690 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 129/400\n",
            " - 0s - loss: 0.6687 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 130/400\n",
            " - 0s - loss: 0.6683 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 131/400\n",
            " - 0s - loss: 0.6680 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 132/400\n",
            " - 0s - loss: 0.6677 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 133/400\n",
            " - 0s - loss: 0.6674 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 134/400\n",
            " - 0s - loss: 0.6670 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 135/400\n",
            " - 0s - loss: 0.6667 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 136/400\n",
            " - 0s - loss: 0.6664 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 137/400\n",
            " - 0s - loss: 0.6660 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 138/400\n",
            " - 0s - loss: 0.6657 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 139/400\n",
            " - 0s - loss: 0.6654 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 140/400\n",
            " - 0s - loss: 0.6650 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 141/400\n",
            " - 0s - loss: 0.6647 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 142/400\n",
            " - 0s - loss: 0.6644 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 143/400\n",
            " - 0s - loss: 0.6641 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 144/400\n",
            " - 0s - loss: 0.6637 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 145/400\n",
            " - 0s - loss: 0.6634 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 146/400\n",
            " - 0s - loss: 0.6631 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 147/400\n",
            " - 0s - loss: 0.6627 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 148/400\n",
            " - 0s - loss: 0.6624 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 149/400\n",
            " - 0s - loss: 0.6621 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 150/400\n",
            " - 0s - loss: 0.6617 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 151/400\n",
            " - 0s - loss: 0.6614 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 152/400\n",
            " - 0s - loss: 0.6611 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 153/400\n",
            " - 0s - loss: 0.6608 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 154/400\n",
            " - 0s - loss: 0.6604 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 155/400\n",
            " - 0s - loss: 0.6601 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 156/400\n",
            " - 0s - loss: 0.6598 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 157/400\n",
            " - 0s - loss: 0.6594 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 158/400\n",
            " - 0s - loss: 0.6591 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 159/400\n",
            " - 0s - loss: 0.6588 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 160/400\n",
            " - 0s - loss: 0.6584 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 161/400\n",
            " - 0s - loss: 0.6581 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 162/400\n",
            " - 0s - loss: 0.6578 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 163/400\n",
            " - 0s - loss: 0.6574 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 164/400\n",
            " - 0s - loss: 0.6571 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 165/400\n",
            " - 0s - loss: 0.6568 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 166/400\n",
            " - 0s - loss: 0.6565 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 167/400\n",
            " - 0s - loss: 0.6561 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 168/400\n",
            " - 0s - loss: 0.6558 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 169/400\n",
            " - 0s - loss: 0.6555 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 170/400\n",
            " - 0s - loss: 0.6551 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 171/400\n",
            " - 0s - loss: 0.6548 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 172/400\n",
            " - 0s - loss: 0.6545 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 173/400\n",
            " - 0s - loss: 0.6541 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 174/400\n",
            " - 0s - loss: 0.6538 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 175/400\n",
            " - 0s - loss: 0.6535 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 176/400\n",
            " - 0s - loss: 0.6531 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 177/400\n",
            " - 0s - loss: 0.6528 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 178/400\n",
            " - 0s - loss: 0.6525 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 179/400\n",
            " - 0s - loss: 0.6521 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 180/400\n",
            " - 0s - loss: 0.6518 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 181/400\n",
            " - 0s - loss: 0.6515 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 182/400\n",
            " - 0s - loss: 0.6512 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 183/400\n",
            " - 0s - loss: 0.6508 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 184/400\n",
            " - 0s - loss: 0.6505 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 185/400\n",
            " - 0s - loss: 0.6502 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 186/400\n",
            " - 0s - loss: 0.6498 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 187/400\n",
            " - 0s - loss: 0.6495 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 188/400\n",
            " - 0s - loss: 0.6492 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 189/400\n",
            " - 0s - loss: 0.6488 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 190/400\n",
            " - 0s - loss: 0.6485 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 191/400\n",
            " - 0s - loss: 0.6482 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 192/400\n",
            " - 0s - loss: 0.6478 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 193/400\n",
            " - 0s - loss: 0.6475 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 194/400\n",
            " - 0s - loss: 0.6472 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 195/400\n",
            " - 0s - loss: 0.6468 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 196/400\n",
            " - 0s - loss: 0.6465 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 197/400\n",
            " - 0s - loss: 0.6462 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 198/400\n",
            " - 0s - loss: 0.6458 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 199/400\n",
            " - 0s - loss: 0.6455 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 200/400\n",
            " - 0s - loss: 0.6452 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 201/400\n",
            " - 0s - loss: 0.6448 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 202/400\n",
            " - 0s - loss: 0.6445 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 203/400\n",
            " - 0s - loss: 0.6442 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 204/400\n",
            " - 0s - loss: 0.6438 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 205/400\n",
            " - 0s - loss: 0.6435 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 206/400\n",
            " - 0s - loss: 0.6432 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 207/400\n",
            " - 0s - loss: 0.6428 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 208/400\n",
            " - 0s - loss: 0.6425 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 209/400\n",
            " - 0s - loss: 0.6422 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 210/400\n",
            " - 0s - loss: 0.6418 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 211/400\n",
            " - 0s - loss: 0.6415 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 212/400\n",
            " - 0s - loss: 0.6412 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 213/400\n",
            " - 0s - loss: 0.6408 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 214/400\n",
            " - 0s - loss: 0.6405 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 215/400\n",
            " - 0s - loss: 0.6402 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 216/400\n",
            " - 0s - loss: 0.6398 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 217/400\n",
            " - 0s - loss: 0.6395 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 218/400\n",
            " - 0s - loss: 0.6391 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 219/400\n",
            " - 0s - loss: 0.6388 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 220/400\n",
            " - 0s - loss: 0.6385 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 221/400\n",
            " - 0s - loss: 0.6381 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 222/400\n",
            " - 0s - loss: 0.6378 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 223/400\n",
            " - 0s - loss: 0.6375 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 224/400\n",
            " - 0s - loss: 0.6371 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 225/400\n",
            " - 0s - loss: 0.6368 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 226/400\n",
            " - 0s - loss: 0.6365 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 227/400\n",
            " - 0s - loss: 0.6361 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 228/400\n",
            " - 0s - loss: 0.6358 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 229/400\n",
            " - 0s - loss: 0.6355 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 230/400\n",
            " - 0s - loss: 0.6351 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 231/400\n",
            " - 0s - loss: 0.6348 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 232/400\n",
            " - 0s - loss: 0.6344 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 233/400\n",
            " - 0s - loss: 0.6341 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 234/400\n",
            " - 0s - loss: 0.6338 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 235/400\n",
            " - 0s - loss: 0.6334 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 236/400\n",
            " - 0s - loss: 0.6331 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 237/400\n",
            " - 0s - loss: 0.6328 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 238/400\n",
            " - 0s - loss: 0.6324 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 239/400\n",
            " - 0s - loss: 0.6321 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 240/400\n",
            " - 0s - loss: 0.6317 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 241/400\n",
            " - 0s - loss: 0.6314 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 242/400\n",
            " - 0s - loss: 0.6311 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 243/400\n",
            " - 0s - loss: 0.6307 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 244/400\n",
            " - 0s - loss: 0.6304 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 245/400\n",
            " - 0s - loss: 0.6301 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 246/400\n",
            " - 0s - loss: 0.6297 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 247/400\n",
            " - 0s - loss: 0.6294 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 248/400\n",
            " - 0s - loss: 0.6290 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 249/400\n",
            " - 0s - loss: 0.6287 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 250/400\n",
            " - 0s - loss: 0.6284 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 251/400\n",
            " - 0s - loss: 0.6280 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 252/400\n",
            " - 0s - loss: 0.6277 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 253/400\n",
            " - 0s - loss: 0.6273 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 254/400\n",
            " - 0s - loss: 0.6270 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 255/400\n",
            " - 0s - loss: 0.6267 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 256/400\n",
            " - 0s - loss: 0.6263 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 257/400\n",
            " - 0s - loss: 0.6260 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 258/400\n",
            " - 0s - loss: 0.6256 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 259/400\n",
            " - 0s - loss: 0.6253 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 260/400\n",
            " - 0s - loss: 0.6250 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 261/400\n",
            " - 0s - loss: 0.6246 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 262/400\n",
            " - 0s - loss: 0.6243 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 263/400\n",
            " - 0s - loss: 0.6239 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 264/400\n",
            " - 0s - loss: 0.6236 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 265/400\n",
            " - 0s - loss: 0.6232 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 266/400\n",
            " - 0s - loss: 0.6229 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 267/400\n",
            " - 0s - loss: 0.6226 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 268/400\n",
            " - 0s - loss: 0.6222 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 269/400\n",
            " - 0s - loss: 0.6219 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 270/400\n",
            " - 0s - loss: 0.6215 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 271/400\n",
            " - 0s - loss: 0.6212 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 272/400\n",
            " - 0s - loss: 0.6208 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 273/400\n",
            " - 0s - loss: 0.6205 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 274/400\n",
            " - 0s - loss: 0.6202 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 275/400\n",
            " - 0s - loss: 0.6198 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 276/400\n",
            " - 0s - loss: 0.6195 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 277/400\n",
            " - 0s - loss: 0.6191 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 278/400\n",
            " - 0s - loss: 0.6188 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 279/400\n",
            " - 0s - loss: 0.6184 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 280/400\n",
            " - 0s - loss: 0.6181 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 281/400\n",
            " - 0s - loss: 0.6177 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 282/400\n",
            " - 0s - loss: 0.6174 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 283/400\n",
            " - 0s - loss: 0.6170 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 284/400\n",
            " - 0s - loss: 0.6167 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 285/400\n",
            " - 0s - loss: 0.6164 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 286/400\n",
            " - 0s - loss: 0.6160 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 287/400\n",
            " - 0s - loss: 0.6157 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 288/400\n",
            " - 0s - loss: 0.6153 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 289/400\n",
            " - 0s - loss: 0.6150 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 290/400\n",
            " - 0s - loss: 0.6146 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 291/400\n",
            " - 0s - loss: 0.6143 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 292/400\n",
            " - 0s - loss: 0.6139 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 293/400\n",
            " - 0s - loss: 0.6136 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 294/400\n",
            " - 0s - loss: 0.6132 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 295/400\n",
            " - 0s - loss: 0.6129 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 296/400\n",
            " - 0s - loss: 0.6125 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 297/400\n",
            " - 0s - loss: 0.6122 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 298/400\n",
            " - 0s - loss: 0.6118 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 299/400\n",
            " - 0s - loss: 0.6115 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 300/400\n",
            " - 0s - loss: 0.6111 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 301/400\n",
            " - 0s - loss: 0.6108 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 302/400\n",
            " - 0s - loss: 0.6104 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 303/400\n",
            " - 0s - loss: 0.6101 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 304/400\n",
            " - 0s - loss: 0.6097 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 305/400\n",
            " - 0s - loss: 0.6094 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 306/400\n",
            " - 0s - loss: 0.6090 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 307/400\n",
            " - 0s - loss: 0.6087 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 308/400\n",
            " - 0s - loss: 0.6083 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 309/400\n",
            " - 0s - loss: 0.6080 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 310/400\n",
            " - 0s - loss: 0.6076 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 311/400\n",
            " - 0s - loss: 0.6073 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 312/400\n",
            " - 0s - loss: 0.6069 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 313/400\n",
            " - 0s - loss: 0.6066 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 314/400\n",
            " - 0s - loss: 0.6062 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 315/400\n",
            " - 0s - loss: 0.6059 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 316/400\n",
            " - 0s - loss: 0.6055 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 317/400\n",
            " - 0s - loss: 0.6052 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 318/400\n",
            " - 0s - loss: 0.6048 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 319/400\n",
            " - 0s - loss: 0.6045 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 320/400\n",
            " - 0s - loss: 0.6041 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 321/400\n",
            " - 0s - loss: 0.6037 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 322/400\n",
            " - 0s - loss: 0.6034 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 323/400\n",
            " - 0s - loss: 0.6030 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 324/400\n",
            " - 0s - loss: 0.6027 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 325/400\n",
            " - 0s - loss: 0.6023 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 326/400\n",
            " - 0s - loss: 0.6020 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 327/400\n",
            " - 0s - loss: 0.6016 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 328/400\n",
            " - 0s - loss: 0.6013 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 329/400\n",
            " - 0s - loss: 0.6009 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 330/400\n",
            " - 0s - loss: 0.6005 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 331/400\n",
            " - 0s - loss: 0.6002 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 332/400\n",
            " - 0s - loss: 0.5998 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 333/400\n",
            " - 0s - loss: 0.5995 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 334/400\n",
            " - 0s - loss: 0.5991 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 335/400\n",
            " - 0s - loss: 0.5987 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 336/400\n",
            " - 0s - loss: 0.5984 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 337/400\n",
            " - 0s - loss: 0.5980 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 338/400\n",
            " - 0s - loss: 0.5977 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 339/400\n",
            " - 0s - loss: 0.5973 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 340/400\n",
            " - 0s - loss: 0.5970 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 341/400\n",
            " - 0s - loss: 0.5966 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 342/400\n",
            " - 0s - loss: 0.5962 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 343/400\n",
            " - 0s - loss: 0.5959 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 344/400\n",
            " - 0s - loss: 0.5955 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 345/400\n",
            " - 0s - loss: 0.5951 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 346/400\n",
            " - 0s - loss: 0.5948 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 347/400\n",
            " - 0s - loss: 0.5944 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 348/400\n",
            " - 0s - loss: 0.5941 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 349/400\n",
            " - 0s - loss: 0.5937 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 350/400\n",
            " - 0s - loss: 0.5933 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 351/400\n",
            " - 0s - loss: 0.5930 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 352/400\n",
            " - 0s - loss: 0.5926 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 353/400\n",
            " - 0s - loss: 0.5922 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 354/400\n",
            " - 0s - loss: 0.5919 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 355/400\n",
            " - 0s - loss: 0.5915 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 356/400\n",
            " - 0s - loss: 0.5912 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 357/400\n",
            " - 0s - loss: 0.5908 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 358/400\n",
            " - 0s - loss: 0.5904 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 359/400\n",
            " - 0s - loss: 0.5901 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 360/400\n",
            " - 0s - loss: 0.5897 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 361/400\n",
            " - 0s - loss: 0.5893 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 362/400\n",
            " - 0s - loss: 0.5890 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 363/400\n",
            " - 0s - loss: 0.5886 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 364/400\n",
            " - 0s - loss: 0.5882 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 365/400\n",
            " - 0s - loss: 0.5879 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 366/400\n",
            " - 0s - loss: 0.5875 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 367/400\n",
            " - 0s - loss: 0.5871 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 368/400\n",
            " - 0s - loss: 0.5867 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 369/400\n",
            " - 0s - loss: 0.5864 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 370/400\n",
            " - 0s - loss: 0.5860 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 371/400\n",
            " - 0s - loss: 0.5856 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 372/400\n",
            " - 0s - loss: 0.5853 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 373/400\n",
            " - 0s - loss: 0.5849 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 374/400\n",
            " - 0s - loss: 0.5845 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 375/400\n",
            " - 0s - loss: 0.5842 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 376/400\n",
            " - 0s - loss: 0.5838 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 377/400\n",
            " - 0s - loss: 0.5834 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 378/400\n",
            " - 0s - loss: 0.5830 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 379/400\n",
            " - 0s - loss: 0.5827 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 380/400\n",
            " - 0s - loss: 0.5823 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 381/400\n",
            " - 0s - loss: 0.5819 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 382/400\n",
            " - 0s - loss: 0.5816 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 383/400\n",
            " - 0s - loss: 0.5812 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 384/400\n",
            " - 0s - loss: 0.5808 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 385/400\n",
            " - 0s - loss: 0.5804 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 386/400\n",
            " - 0s - loss: 0.5801 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 387/400\n",
            " - 0s - loss: 0.5797 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 388/400\n",
            " - 0s - loss: 0.5793 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 389/400\n",
            " - 0s - loss: 0.5789 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 390/400\n",
            " - 0s - loss: 0.5786 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 391/400\n",
            " - 0s - loss: 0.5782 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 392/400\n",
            " - 0s - loss: 0.5778 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 393/400\n",
            " - 0s - loss: 0.5774 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 394/400\n",
            " - 0s - loss: 0.5771 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 395/400\n",
            " - 0s - loss: 0.5767 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 396/400\n",
            " - 0s - loss: 0.5763 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 397/400\n",
            " - 0s - loss: 0.5759 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 398/400\n",
            " - 0s - loss: 0.5755 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 399/400\n",
            " - 0s - loss: 0.5752 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 400/400\n",
            " - 0s - loss: 0.5748 - sparse_top_k_categorical_accuracy: 0.5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MljdGHXMUwYr",
        "colab_type": "text"
      },
      "source": [
        "#cosine_proximity\n",
        "\n",
        "keras.metrics.cosine_proximity(y_true, y_pred, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfLN9tE6UyQl",
        "colab_type": "code",
        "outputId": "d3561586-32b8-48ae-d69a-1abcd4b24c4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from matplotlib import pyplot\n",
        "# prepare sequence\n",
        "X = array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
        "y = array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(2, input_dim=1))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['cosine_proximity'])\n",
        "# train model\n",
        "history = model.fit(X, y, epochs=400, batch_size=len(X), verbose=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            " - 0s - loss: 0.7432 - cosine_proximity: -5.0000e-01\n",
            "Epoch 2/400\n",
            " - 0s - loss: 0.7429 - cosine_proximity: -5.0000e-01\n",
            "Epoch 3/400\n",
            " - 0s - loss: 0.7425 - cosine_proximity: -5.0000e-01\n",
            "Epoch 4/400\n",
            " - 0s - loss: 0.7421 - cosine_proximity: -5.0000e-01\n",
            "Epoch 5/400\n",
            " - 0s - loss: 0.7417 - cosine_proximity: -5.0000e-01\n",
            "Epoch 6/400\n",
            " - 0s - loss: 0.7413 - cosine_proximity: -5.0000e-01\n",
            "Epoch 7/400\n",
            " - 0s - loss: 0.7409 - cosine_proximity: -5.0000e-01\n",
            "Epoch 8/400\n",
            " - 0s - loss: 0.7405 - cosine_proximity: -5.0000e-01\n",
            "Epoch 9/400\n",
            " - 0s - loss: 0.7401 - cosine_proximity: -5.0000e-01\n",
            "Epoch 10/400\n",
            " - 0s - loss: 0.7397 - cosine_proximity: -5.0000e-01\n",
            "Epoch 11/400\n",
            " - 0s - loss: 0.7393 - cosine_proximity: -5.0000e-01\n",
            "Epoch 12/400\n",
            " - 0s - loss: 0.7389 - cosine_proximity: -5.0000e-01\n",
            "Epoch 13/400\n",
            " - 0s - loss: 0.7385 - cosine_proximity: -5.0000e-01\n",
            "Epoch 14/400\n",
            " - 0s - loss: 0.7381 - cosine_proximity: -5.0000e-01\n",
            "Epoch 15/400\n",
            " - 0s - loss: 0.7377 - cosine_proximity: -5.0000e-01\n",
            "Epoch 16/400\n",
            " - 0s - loss: 0.7373 - cosine_proximity: -5.0000e-01\n",
            "Epoch 17/400\n",
            " - 0s - loss: 0.7369 - cosine_proximity: -5.0000e-01\n",
            "Epoch 18/400\n",
            " - 0s - loss: 0.7365 - cosine_proximity: -5.0000e-01\n",
            "Epoch 19/400\n",
            " - 0s - loss: 0.7361 - cosine_proximity: -5.0000e-01\n",
            "Epoch 20/400\n",
            " - 0s - loss: 0.7357 - cosine_proximity: -5.0000e-01\n",
            "Epoch 21/400\n",
            " - 0s - loss: 0.7353 - cosine_proximity: -5.0000e-01\n",
            "Epoch 22/400\n",
            " - 0s - loss: 0.7349 - cosine_proximity: -5.0000e-01\n",
            "Epoch 23/400\n",
            " - 0s - loss: 0.7345 - cosine_proximity: -5.0000e-01\n",
            "Epoch 24/400\n",
            " - 0s - loss: 0.7342 - cosine_proximity: -5.0000e-01\n",
            "Epoch 25/400\n",
            " - 0s - loss: 0.7338 - cosine_proximity: -5.0000e-01\n",
            "Epoch 26/400\n",
            " - 0s - loss: 0.7334 - cosine_proximity: -5.0000e-01\n",
            "Epoch 27/400\n",
            " - 0s - loss: 0.7331 - cosine_proximity: -5.0000e-01\n",
            "Epoch 28/400\n",
            " - 0s - loss: 0.7327 - cosine_proximity: -5.0000e-01\n",
            "Epoch 29/400\n",
            " - 0s - loss: 0.7323 - cosine_proximity: -5.0000e-01\n",
            "Epoch 30/400\n",
            " - 0s - loss: 0.7320 - cosine_proximity: -5.0000e-01\n",
            "Epoch 31/400\n",
            " - 0s - loss: 0.7316 - cosine_proximity: -5.0000e-01\n",
            "Epoch 32/400\n",
            " - 0s - loss: 0.7313 - cosine_proximity: -5.0000e-01\n",
            "Epoch 33/400\n",
            " - 0s - loss: 0.7309 - cosine_proximity: -5.0000e-01\n",
            "Epoch 34/400\n",
            " - 0s - loss: 0.7306 - cosine_proximity: -5.0000e-01\n",
            "Epoch 35/400\n",
            " - 0s - loss: 0.7302 - cosine_proximity: -5.0000e-01\n",
            "Epoch 36/400\n",
            " - 0s - loss: 0.7299 - cosine_proximity: -5.0000e-01\n",
            "Epoch 37/400\n",
            " - 0s - loss: 0.7296 - cosine_proximity: -5.0000e-01\n",
            "Epoch 38/400\n",
            " - 0s - loss: 0.7292 - cosine_proximity: -5.0000e-01\n",
            "Epoch 39/400\n",
            " - 0s - loss: 0.7289 - cosine_proximity: -5.0000e-01\n",
            "Epoch 40/400\n",
            " - 0s - loss: 0.7286 - cosine_proximity: -5.0000e-01\n",
            "Epoch 41/400\n",
            " - 0s - loss: 0.7282 - cosine_proximity: -5.0000e-01\n",
            "Epoch 42/400\n",
            " - 0s - loss: 0.7279 - cosine_proximity: -5.0000e-01\n",
            "Epoch 43/400\n",
            " - 0s - loss: 0.7276 - cosine_proximity: -5.0000e-01\n",
            "Epoch 44/400\n",
            " - 0s - loss: 0.7273 - cosine_proximity: -5.0000e-01\n",
            "Epoch 45/400\n",
            " - 0s - loss: 0.7269 - cosine_proximity: -5.0000e-01\n",
            "Epoch 46/400\n",
            " - 0s - loss: 0.7266 - cosine_proximity: -5.0000e-01\n",
            "Epoch 47/400\n",
            " - 0s - loss: 0.7263 - cosine_proximity: -5.0000e-01\n",
            "Epoch 48/400\n",
            " - 0s - loss: 0.7260 - cosine_proximity: -5.0000e-01\n",
            "Epoch 49/400\n",
            " - 0s - loss: 0.7257 - cosine_proximity: -5.0000e-01\n",
            "Epoch 50/400\n",
            " - 0s - loss: 0.7254 - cosine_proximity: -5.0000e-01\n",
            "Epoch 51/400\n",
            " - 0s - loss: 0.7251 - cosine_proximity: -5.0000e-01\n",
            "Epoch 52/400\n",
            " - 0s - loss: 0.7248 - cosine_proximity: -5.0000e-01\n",
            "Epoch 53/400\n",
            " - 0s - loss: 0.7245 - cosine_proximity: -5.0000e-01\n",
            "Epoch 54/400\n",
            " - 0s - loss: 0.7242 - cosine_proximity: -5.0000e-01\n",
            "Epoch 55/400\n",
            " - 0s - loss: 0.7239 - cosine_proximity: -5.0000e-01\n",
            "Epoch 56/400\n",
            " - 0s - loss: 0.7236 - cosine_proximity: -5.0000e-01\n",
            "Epoch 57/400\n",
            " - 0s - loss: 0.7233 - cosine_proximity: -5.0000e-01\n",
            "Epoch 58/400\n",
            " - 0s - loss: 0.7230 - cosine_proximity: -5.0000e-01\n",
            "Epoch 59/400\n",
            " - 0s - loss: 0.7227 - cosine_proximity: -5.0000e-01\n",
            "Epoch 60/400\n",
            " - 0s - loss: 0.7225 - cosine_proximity: -5.0000e-01\n",
            "Epoch 61/400\n",
            " - 0s - loss: 0.7222 - cosine_proximity: -5.0000e-01\n",
            "Epoch 62/400\n",
            " - 0s - loss: 0.7219 - cosine_proximity: -5.0000e-01\n",
            "Epoch 63/400\n",
            " - 0s - loss: 0.7216 - cosine_proximity: -5.0000e-01\n",
            "Epoch 64/400\n",
            " - 0s - loss: 0.7213 - cosine_proximity: -5.0000e-01\n",
            "Epoch 65/400\n",
            " - 0s - loss: 0.7211 - cosine_proximity: -5.0000e-01\n",
            "Epoch 66/400\n",
            " - 0s - loss: 0.7208 - cosine_proximity: -5.0000e-01\n",
            "Epoch 67/400\n",
            " - 0s - loss: 0.7205 - cosine_proximity: -5.0000e-01\n",
            "Epoch 68/400\n",
            " - 0s - loss: 0.7202 - cosine_proximity: -5.0000e-01\n",
            "Epoch 69/400\n",
            " - 0s - loss: 0.7200 - cosine_proximity: -5.0000e-01\n",
            "Epoch 70/400\n",
            " - 0s - loss: 0.7197 - cosine_proximity: -5.0000e-01\n",
            "Epoch 71/400\n",
            " - 0s - loss: 0.7194 - cosine_proximity: -5.0000e-01\n",
            "Epoch 72/400\n",
            " - 0s - loss: 0.7191 - cosine_proximity: -5.0000e-01\n",
            "Epoch 73/400\n",
            " - 0s - loss: 0.7189 - cosine_proximity: -5.0000e-01\n",
            "Epoch 74/400\n",
            " - 0s - loss: 0.7186 - cosine_proximity: -5.0000e-01\n",
            "Epoch 75/400\n",
            " - 0s - loss: 0.7184 - cosine_proximity: -5.0000e-01\n",
            "Epoch 76/400\n",
            " - 0s - loss: 0.7181 - cosine_proximity: -5.0000e-01\n",
            "Epoch 77/400\n",
            " - 0s - loss: 0.7178 - cosine_proximity: -5.0000e-01\n",
            "Epoch 78/400\n",
            " - 0s - loss: 0.7176 - cosine_proximity: -5.0000e-01\n",
            "Epoch 79/400\n",
            " - 0s - loss: 0.7173 - cosine_proximity: -5.0000e-01\n",
            "Epoch 80/400\n",
            " - 0s - loss: 0.7170 - cosine_proximity: -5.0000e-01\n",
            "Epoch 81/400\n",
            " - 0s - loss: 0.7168 - cosine_proximity: -5.0000e-01\n",
            "Epoch 82/400\n",
            " - 0s - loss: 0.7165 - cosine_proximity: -5.0000e-01\n",
            "Epoch 83/400\n",
            " - 0s - loss: 0.7163 - cosine_proximity: -5.0000e-01\n",
            "Epoch 84/400\n",
            " - 0s - loss: 0.7160 - cosine_proximity: -5.0000e-01\n",
            "Epoch 85/400\n",
            " - 0s - loss: 0.7157 - cosine_proximity: -5.0000e-01\n",
            "Epoch 86/400\n",
            " - 0s - loss: 0.7155 - cosine_proximity: -5.0000e-01\n",
            "Epoch 87/400\n",
            " - 0s - loss: 0.7152 - cosine_proximity: -5.0000e-01\n",
            "Epoch 88/400\n",
            " - 0s - loss: 0.7150 - cosine_proximity: -5.0000e-01\n",
            "Epoch 89/400\n",
            " - 0s - loss: 0.7147 - cosine_proximity: -5.0000e-01\n",
            "Epoch 90/400\n",
            " - 0s - loss: 0.7145 - cosine_proximity: -5.0000e-01\n",
            "Epoch 91/400\n",
            " - 0s - loss: 0.7142 - cosine_proximity: -5.0000e-01\n",
            "Epoch 92/400\n",
            " - 0s - loss: 0.7140 - cosine_proximity: -5.0000e-01\n",
            "Epoch 93/400\n",
            " - 0s - loss: 0.7137 - cosine_proximity: -5.0000e-01\n",
            "Epoch 94/400\n",
            " - 0s - loss: 0.7134 - cosine_proximity: -5.0000e-01\n",
            "Epoch 95/400\n",
            " - 0s - loss: 0.7132 - cosine_proximity: -5.0000e-01\n",
            "Epoch 96/400\n",
            " - 0s - loss: 0.7129 - cosine_proximity: -5.0000e-01\n",
            "Epoch 97/400\n",
            " - 0s - loss: 0.7127 - cosine_proximity: -5.0000e-01\n",
            "Epoch 98/400\n",
            " - 0s - loss: 0.7124 - cosine_proximity: -5.0000e-01\n",
            "Epoch 99/400\n",
            " - 0s - loss: 0.7122 - cosine_proximity: -5.0000e-01\n",
            "Epoch 100/400\n",
            " - 0s - loss: 0.7119 - cosine_proximity: -5.0000e-01\n",
            "Epoch 101/400\n",
            " - 0s - loss: 0.7117 - cosine_proximity: -5.0000e-01\n",
            "Epoch 102/400\n",
            " - 0s - loss: 0.7114 - cosine_proximity: -5.0000e-01\n",
            "Epoch 103/400\n",
            " - 0s - loss: 0.7112 - cosine_proximity: -5.0000e-01\n",
            "Epoch 104/400\n",
            " - 0s - loss: 0.7109 - cosine_proximity: -5.0000e-01\n",
            "Epoch 105/400\n",
            " - 0s - loss: 0.7107 - cosine_proximity: -5.0000e-01\n",
            "Epoch 106/400\n",
            " - 0s - loss: 0.7104 - cosine_proximity: -5.0000e-01\n",
            "Epoch 107/400\n",
            " - 0s - loss: 0.7102 - cosine_proximity: -5.0000e-01\n",
            "Epoch 108/400\n",
            " - 0s - loss: 0.7099 - cosine_proximity: -5.0000e-01\n",
            "Epoch 109/400\n",
            " - 0s - loss: 0.7097 - cosine_proximity: -5.0000e-01\n",
            "Epoch 110/400\n",
            " - 0s - loss: 0.7094 - cosine_proximity: -5.0000e-01\n",
            "Epoch 111/400\n",
            " - 0s - loss: 0.7092 - cosine_proximity: -5.0000e-01\n",
            "Epoch 112/400\n",
            " - 0s - loss: 0.7089 - cosine_proximity: -5.0000e-01\n",
            "Epoch 113/400\n",
            " - 0s - loss: 0.7086 - cosine_proximity: -5.0000e-01\n",
            "Epoch 114/400\n",
            " - 0s - loss: 0.7084 - cosine_proximity: -5.0000e-01\n",
            "Epoch 115/400\n",
            " - 0s - loss: 0.7081 - cosine_proximity: -5.0000e-01\n",
            "Epoch 116/400\n",
            " - 0s - loss: 0.7079 - cosine_proximity: -5.0000e-01\n",
            "Epoch 117/400\n",
            " - 0s - loss: 0.7076 - cosine_proximity: -5.0000e-01\n",
            "Epoch 118/400\n",
            " - 0s - loss: 0.7074 - cosine_proximity: -5.0000e-01\n",
            "Epoch 119/400\n",
            " - 0s - loss: 0.7071 - cosine_proximity: -5.0000e-01\n",
            "Epoch 120/400\n",
            " - 0s - loss: 0.7069 - cosine_proximity: -5.0000e-01\n",
            "Epoch 121/400\n",
            " - 0s - loss: 0.7066 - cosine_proximity: -5.0000e-01\n",
            "Epoch 122/400\n",
            " - 0s - loss: 0.7064 - cosine_proximity: -5.0000e-01\n",
            "Epoch 123/400\n",
            " - 0s - loss: 0.7061 - cosine_proximity: -5.0000e-01\n",
            "Epoch 124/400\n",
            " - 0s - loss: 0.7059 - cosine_proximity: -5.0000e-01\n",
            "Epoch 125/400\n",
            " - 0s - loss: 0.7056 - cosine_proximity: -5.0000e-01\n",
            "Epoch 126/400\n",
            " - 0s - loss: 0.7054 - cosine_proximity: -5.0000e-01\n",
            "Epoch 127/400\n",
            " - 0s - loss: 0.7051 - cosine_proximity: -5.0000e-01\n",
            "Epoch 128/400\n",
            " - 0s - loss: 0.7048 - cosine_proximity: -5.0000e-01\n",
            "Epoch 129/400\n",
            " - 0s - loss: 0.7046 - cosine_proximity: -5.0000e-01\n",
            "Epoch 130/400\n",
            " - 0s - loss: 0.7043 - cosine_proximity: -5.0000e-01\n",
            "Epoch 131/400\n",
            " - 0s - loss: 0.7041 - cosine_proximity: -5.0000e-01\n",
            "Epoch 132/400\n",
            " - 0s - loss: 0.7038 - cosine_proximity: -5.0000e-01\n",
            "Epoch 133/400\n",
            " - 0s - loss: 0.7036 - cosine_proximity: -5.0000e-01\n",
            "Epoch 134/400\n",
            " - 0s - loss: 0.7033 - cosine_proximity: -5.0000e-01\n",
            "Epoch 135/400\n",
            " - 0s - loss: 0.7031 - cosine_proximity: -5.0000e-01\n",
            "Epoch 136/400\n",
            " - 0s - loss: 0.7028 - cosine_proximity: -5.0000e-01\n",
            "Epoch 137/400\n",
            " - 0s - loss: 0.7026 - cosine_proximity: -5.0000e-01\n",
            "Epoch 138/400\n",
            " - 0s - loss: 0.7023 - cosine_proximity: -5.0000e-01\n",
            "Epoch 139/400\n",
            " - 0s - loss: 0.7020 - cosine_proximity: -5.0000e-01\n",
            "Epoch 140/400\n",
            " - 0s - loss: 0.7018 - cosine_proximity: -5.0000e-01\n",
            "Epoch 141/400\n",
            " - 0s - loss: 0.7015 - cosine_proximity: -5.0000e-01\n",
            "Epoch 142/400\n",
            " - 0s - loss: 0.7013 - cosine_proximity: -5.0000e-01\n",
            "Epoch 143/400\n",
            " - 0s - loss: 0.7010 - cosine_proximity: -5.0000e-01\n",
            "Epoch 144/400\n",
            " - 0s - loss: 0.7008 - cosine_proximity: -5.0000e-01\n",
            "Epoch 145/400\n",
            " - 0s - loss: 0.7005 - cosine_proximity: -5.0000e-01\n",
            "Epoch 146/400\n",
            " - 0s - loss: 0.7002 - cosine_proximity: -5.0000e-01\n",
            "Epoch 147/400\n",
            " - 0s - loss: 0.7000 - cosine_proximity: -5.0000e-01\n",
            "Epoch 148/400\n",
            " - 0s - loss: 0.6997 - cosine_proximity: -5.0000e-01\n",
            "Epoch 149/400\n",
            " - 0s - loss: 0.6995 - cosine_proximity: -5.0000e-01\n",
            "Epoch 150/400\n",
            " - 0s - loss: 0.6992 - cosine_proximity: -5.0000e-01\n",
            "Epoch 151/400\n",
            " - 0s - loss: 0.6989 - cosine_proximity: -5.0000e-01\n",
            "Epoch 152/400\n",
            " - 0s - loss: 0.6987 - cosine_proximity: -5.0000e-01\n",
            "Epoch 153/400\n",
            " - 0s - loss: 0.6984 - cosine_proximity: -5.0000e-01\n",
            "Epoch 154/400\n",
            " - 0s - loss: 0.6982 - cosine_proximity: -5.0000e-01\n",
            "Epoch 155/400\n",
            " - 0s - loss: 0.6979 - cosine_proximity: -5.0000e-01\n",
            "Epoch 156/400\n",
            " - 0s - loss: 0.6976 - cosine_proximity: -5.0000e-01\n",
            "Epoch 157/400\n",
            " - 0s - loss: 0.6974 - cosine_proximity: -5.0000e-01\n",
            "Epoch 158/400\n",
            " - 0s - loss: 0.6971 - cosine_proximity: -5.0000e-01\n",
            "Epoch 159/400\n",
            " - 0s - loss: 0.6969 - cosine_proximity: -5.0000e-01\n",
            "Epoch 160/400\n",
            " - 0s - loss: 0.6966 - cosine_proximity: -5.0000e-01\n",
            "Epoch 161/400\n",
            " - 0s - loss: 0.6963 - cosine_proximity: -5.0000e-01\n",
            "Epoch 162/400\n",
            " - 0s - loss: 0.6961 - cosine_proximity: -5.0000e-01\n",
            "Epoch 163/400\n",
            " - 0s - loss: 0.6958 - cosine_proximity: -5.0000e-01\n",
            "Epoch 164/400\n",
            " - 0s - loss: 0.6956 - cosine_proximity: -5.0000e-01\n",
            "Epoch 165/400\n",
            " - 0s - loss: 0.6953 - cosine_proximity: -5.0000e-01\n",
            "Epoch 166/400\n",
            " - 0s - loss: 0.6950 - cosine_proximity: -5.0000e-01\n",
            "Epoch 167/400\n",
            " - 0s - loss: 0.6948 - cosine_proximity: -5.0000e-01\n",
            "Epoch 168/400\n",
            " - 0s - loss: 0.6945 - cosine_proximity: -5.0000e-01\n",
            "Epoch 169/400\n",
            " - 0s - loss: 0.6942 - cosine_proximity: -5.0000e-01\n",
            "Epoch 170/400\n",
            " - 0s - loss: 0.6940 - cosine_proximity: -5.0000e-01\n",
            "Epoch 171/400\n",
            " - 0s - loss: 0.6937 - cosine_proximity: -5.0000e-01\n",
            "Epoch 172/400\n",
            " - 0s - loss: 0.6935 - cosine_proximity: -5.0000e-01\n",
            "Epoch 173/400\n",
            " - 0s - loss: 0.6932 - cosine_proximity: -5.0000e-01\n",
            "Epoch 174/400\n",
            " - 0s - loss: 0.6929 - cosine_proximity: -5.0000e-01\n",
            "Epoch 175/400\n",
            " - 0s - loss: 0.6927 - cosine_proximity: -5.0000e-01\n",
            "Epoch 176/400\n",
            " - 0s - loss: 0.6924 - cosine_proximity: -5.0000e-01\n",
            "Epoch 177/400\n",
            " - 0s - loss: 0.6921 - cosine_proximity: -5.0000e-01\n",
            "Epoch 178/400\n",
            " - 0s - loss: 0.6919 - cosine_proximity: -5.0000e-01\n",
            "Epoch 179/400\n",
            " - 0s - loss: 0.6916 - cosine_proximity: -5.0000e-01\n",
            "Epoch 180/400\n",
            " - 0s - loss: 0.6913 - cosine_proximity: -5.0000e-01\n",
            "Epoch 181/400\n",
            " - 0s - loss: 0.6911 - cosine_proximity: -5.0000e-01\n",
            "Epoch 182/400\n",
            " - 0s - loss: 0.6908 - cosine_proximity: -5.0000e-01\n",
            "Epoch 183/400\n",
            " - 0s - loss: 0.6905 - cosine_proximity: -5.0000e-01\n",
            "Epoch 184/400\n",
            " - 0s - loss: 0.6903 - cosine_proximity: -5.0000e-01\n",
            "Epoch 185/400\n",
            " - 0s - loss: 0.6900 - cosine_proximity: -5.0000e-01\n",
            "Epoch 186/400\n",
            " - 0s - loss: 0.6897 - cosine_proximity: -5.0000e-01\n",
            "Epoch 187/400\n",
            " - 0s - loss: 0.6895 - cosine_proximity: -5.0000e-01\n",
            "Epoch 188/400\n",
            " - 0s - loss: 0.6892 - cosine_proximity: -5.0000e-01\n",
            "Epoch 189/400\n",
            " - 0s - loss: 0.6889 - cosine_proximity: -5.0000e-01\n",
            "Epoch 190/400\n",
            " - 0s - loss: 0.6887 - cosine_proximity: -5.0000e-01\n",
            "Epoch 191/400\n",
            " - 0s - loss: 0.6884 - cosine_proximity: -5.0000e-01\n",
            "Epoch 192/400\n",
            " - 0s - loss: 0.6881 - cosine_proximity: -5.0000e-01\n",
            "Epoch 193/400\n",
            " - 0s - loss: 0.6879 - cosine_proximity: -5.0000e-01\n",
            "Epoch 194/400\n",
            " - 0s - loss: 0.6876 - cosine_proximity: -5.0000e-01\n",
            "Epoch 195/400\n",
            " - 0s - loss: 0.6873 - cosine_proximity: -5.0000e-01\n",
            "Epoch 196/400\n",
            " - 0s - loss: 0.6871 - cosine_proximity: -5.0000e-01\n",
            "Epoch 197/400\n",
            " - 0s - loss: 0.6868 - cosine_proximity: -5.0000e-01\n",
            "Epoch 198/400\n",
            " - 0s - loss: 0.6865 - cosine_proximity: -5.0000e-01\n",
            "Epoch 199/400\n",
            " - 0s - loss: 0.6863 - cosine_proximity: -5.0000e-01\n",
            "Epoch 200/400\n",
            " - 0s - loss: 0.6860 - cosine_proximity: -5.0000e-01\n",
            "Epoch 201/400\n",
            " - 0s - loss: 0.6857 - cosine_proximity: -5.0000e-01\n",
            "Epoch 202/400\n",
            " - 0s - loss: 0.6855 - cosine_proximity: -5.0000e-01\n",
            "Epoch 203/400\n",
            " - 0s - loss: 0.6852 - cosine_proximity: -5.0000e-01\n",
            "Epoch 204/400\n",
            " - 0s - loss: 0.6849 - cosine_proximity: -5.0000e-01\n",
            "Epoch 205/400\n",
            " - 0s - loss: 0.6846 - cosine_proximity: -5.0000e-01\n",
            "Epoch 206/400\n",
            " - 0s - loss: 0.6844 - cosine_proximity: -5.0000e-01\n",
            "Epoch 207/400\n",
            " - 0s - loss: 0.6841 - cosine_proximity: -5.0000e-01\n",
            "Epoch 208/400\n",
            " - 0s - loss: 0.6838 - cosine_proximity: -5.0000e-01\n",
            "Epoch 209/400\n",
            " - 0s - loss: 0.6836 - cosine_proximity: -5.0000e-01\n",
            "Epoch 210/400\n",
            " - 0s - loss: 0.6833 - cosine_proximity: -5.0000e-01\n",
            "Epoch 211/400\n",
            " - 0s - loss: 0.6830 - cosine_proximity: -5.0000e-01\n",
            "Epoch 212/400\n",
            " - 0s - loss: 0.6827 - cosine_proximity: -5.0000e-01\n",
            "Epoch 213/400\n",
            " - 0s - loss: 0.6825 - cosine_proximity: -5.0000e-01\n",
            "Epoch 214/400\n",
            " - 0s - loss: 0.6822 - cosine_proximity: -5.0000e-01\n",
            "Epoch 215/400\n",
            " - 0s - loss: 0.6819 - cosine_proximity: -5.0000e-01\n",
            "Epoch 216/400\n",
            " - 0s - loss: 0.6816 - cosine_proximity: -5.0000e-01\n",
            "Epoch 217/400\n",
            " - 0s - loss: 0.6814 - cosine_proximity: -5.0000e-01\n",
            "Epoch 218/400\n",
            " - 0s - loss: 0.6811 - cosine_proximity: -5.0000e-01\n",
            "Epoch 219/400\n",
            " - 0s - loss: 0.6808 - cosine_proximity: -5.0000e-01\n",
            "Epoch 220/400\n",
            " - 0s - loss: 0.6806 - cosine_proximity: -5.0000e-01\n",
            "Epoch 221/400\n",
            " - 0s - loss: 0.6803 - cosine_proximity: -5.0000e-01\n",
            "Epoch 222/400\n",
            " - 0s - loss: 0.6800 - cosine_proximity: -5.0000e-01\n",
            "Epoch 223/400\n",
            " - 0s - loss: 0.6797 - cosine_proximity: -5.0000e-01\n",
            "Epoch 224/400\n",
            " - 0s - loss: 0.6795 - cosine_proximity: -5.0000e-01\n",
            "Epoch 225/400\n",
            " - 0s - loss: 0.6792 - cosine_proximity: -5.0000e-01\n",
            "Epoch 226/400\n",
            " - 0s - loss: 0.6789 - cosine_proximity: -5.0000e-01\n",
            "Epoch 227/400\n",
            " - 0s - loss: 0.6786 - cosine_proximity: -5.0000e-01\n",
            "Epoch 228/400\n",
            " - 0s - loss: 0.6784 - cosine_proximity: -5.0000e-01\n",
            "Epoch 229/400\n",
            " - 0s - loss: 0.6781 - cosine_proximity: -5.0000e-01\n",
            "Epoch 230/400\n",
            " - 0s - loss: 0.6778 - cosine_proximity: -5.0000e-01\n",
            "Epoch 231/400\n",
            " - 0s - loss: 0.6775 - cosine_proximity: -5.0000e-01\n",
            "Epoch 232/400\n",
            " - 0s - loss: 0.6773 - cosine_proximity: -5.0000e-01\n",
            "Epoch 233/400\n",
            " - 0s - loss: 0.6770 - cosine_proximity: -5.0000e-01\n",
            "Epoch 234/400\n",
            " - 0s - loss: 0.6767 - cosine_proximity: -5.0000e-01\n",
            "Epoch 235/400\n",
            " - 0s - loss: 0.6764 - cosine_proximity: -5.0000e-01\n",
            "Epoch 236/400\n",
            " - 0s - loss: 0.6761 - cosine_proximity: -5.0000e-01\n",
            "Epoch 237/400\n",
            " - 0s - loss: 0.6759 - cosine_proximity: -5.0000e-01\n",
            "Epoch 238/400\n",
            " - 0s - loss: 0.6756 - cosine_proximity: -5.0000e-01\n",
            "Epoch 239/400\n",
            " - 0s - loss: 0.6753 - cosine_proximity: -5.0000e-01\n",
            "Epoch 240/400\n",
            " - 0s - loss: 0.6750 - cosine_proximity: -5.0000e-01\n",
            "Epoch 241/400\n",
            " - 0s - loss: 0.6748 - cosine_proximity: -5.0000e-01\n",
            "Epoch 242/400\n",
            " - 0s - loss: 0.6745 - cosine_proximity: -5.0000e-01\n",
            "Epoch 243/400\n",
            " - 0s - loss: 0.6742 - cosine_proximity: -5.0000e-01\n",
            "Epoch 244/400\n",
            " - 0s - loss: 0.6739 - cosine_proximity: -5.0000e-01\n",
            "Epoch 245/400\n",
            " - 0s - loss: 0.6736 - cosine_proximity: -5.0000e-01\n",
            "Epoch 246/400\n",
            " - 0s - loss: 0.6734 - cosine_proximity: -5.0000e-01\n",
            "Epoch 247/400\n",
            " - 0s - loss: 0.6731 - cosine_proximity: -5.0000e-01\n",
            "Epoch 248/400\n",
            " - 0s - loss: 0.6728 - cosine_proximity: -5.0000e-01\n",
            "Epoch 249/400\n",
            " - 0s - loss: 0.6725 - cosine_proximity: -5.0000e-01\n",
            "Epoch 250/400\n",
            " - 0s - loss: 0.6722 - cosine_proximity: -5.0000e-01\n",
            "Epoch 251/400\n",
            " - 0s - loss: 0.6720 - cosine_proximity: -5.0000e-01\n",
            "Epoch 252/400\n",
            " - 0s - loss: 0.6717 - cosine_proximity: -5.0000e-01\n",
            "Epoch 253/400\n",
            " - 0s - loss: 0.6714 - cosine_proximity: -5.0000e-01\n",
            "Epoch 254/400\n",
            " - 0s - loss: 0.6711 - cosine_proximity: -5.0000e-01\n",
            "Epoch 255/400\n",
            " - 0s - loss: 0.6708 - cosine_proximity: -5.0000e-01\n",
            "Epoch 256/400\n",
            " - 0s - loss: 0.6706 - cosine_proximity: -5.0000e-01\n",
            "Epoch 257/400\n",
            " - 0s - loss: 0.6703 - cosine_proximity: -5.0000e-01\n",
            "Epoch 258/400\n",
            " - 0s - loss: 0.6700 - cosine_proximity: -5.0000e-01\n",
            "Epoch 259/400\n",
            " - 0s - loss: 0.6697 - cosine_proximity: -5.0000e-01\n",
            "Epoch 260/400\n",
            " - 0s - loss: 0.6694 - cosine_proximity: -5.0000e-01\n",
            "Epoch 261/400\n",
            " - 0s - loss: 0.6691 - cosine_proximity: -5.0000e-01\n",
            "Epoch 262/400\n",
            " - 0s - loss: 0.6689 - cosine_proximity: -5.0000e-01\n",
            "Epoch 263/400\n",
            " - 0s - loss: 0.6686 - cosine_proximity: -5.0000e-01\n",
            "Epoch 264/400\n",
            " - 0s - loss: 0.6683 - cosine_proximity: -5.0000e-01\n",
            "Epoch 265/400\n",
            " - 0s - loss: 0.6680 - cosine_proximity: -5.0000e-01\n",
            "Epoch 266/400\n",
            " - 0s - loss: 0.6677 - cosine_proximity: -5.0000e-01\n",
            "Epoch 267/400\n",
            " - 0s - loss: 0.6674 - cosine_proximity: -5.0000e-01\n",
            "Epoch 268/400\n",
            " - 0s - loss: 0.6672 - cosine_proximity: -5.0000e-01\n",
            "Epoch 269/400\n",
            " - 0s - loss: 0.6669 - cosine_proximity: -5.0000e-01\n",
            "Epoch 270/400\n",
            " - 0s - loss: 0.6666 - cosine_proximity: -5.0000e-01\n",
            "Epoch 271/400\n",
            " - 0s - loss: 0.6663 - cosine_proximity: -5.0000e-01\n",
            "Epoch 272/400\n",
            " - 0s - loss: 0.6660 - cosine_proximity: -5.0000e-01\n",
            "Epoch 273/400\n",
            " - 0s - loss: 0.6657 - cosine_proximity: -5.0000e-01\n",
            "Epoch 274/400\n",
            " - 0s - loss: 0.6654 - cosine_proximity: -5.0000e-01\n",
            "Epoch 275/400\n",
            " - 0s - loss: 0.6652 - cosine_proximity: -5.0000e-01\n",
            "Epoch 276/400\n",
            " - 0s - loss: 0.6649 - cosine_proximity: -5.0000e-01\n",
            "Epoch 277/400\n",
            " - 0s - loss: 0.6646 - cosine_proximity: -5.0000e-01\n",
            "Epoch 278/400\n",
            " - 0s - loss: 0.6643 - cosine_proximity: -5.0000e-01\n",
            "Epoch 279/400\n",
            " - 0s - loss: 0.6640 - cosine_proximity: -5.0000e-01\n",
            "Epoch 280/400\n",
            " - 0s - loss: 0.6637 - cosine_proximity: -5.0000e-01\n",
            "Epoch 281/400\n",
            " - 0s - loss: 0.6634 - cosine_proximity: -5.0000e-01\n",
            "Epoch 282/400\n",
            " - 0s - loss: 0.6632 - cosine_proximity: -5.0000e-01\n",
            "Epoch 283/400\n",
            " - 0s - loss: 0.6629 - cosine_proximity: -5.0000e-01\n",
            "Epoch 284/400\n",
            " - 0s - loss: 0.6626 - cosine_proximity: -5.0000e-01\n",
            "Epoch 285/400\n",
            " - 0s - loss: 0.6623 - cosine_proximity: -5.0000e-01\n",
            "Epoch 286/400\n",
            " - 0s - loss: 0.6620 - cosine_proximity: -5.0000e-01\n",
            "Epoch 287/400\n",
            " - 0s - loss: 0.6617 - cosine_proximity: -5.0000e-01\n",
            "Epoch 288/400\n",
            " - 0s - loss: 0.6614 - cosine_proximity: -5.0000e-01\n",
            "Epoch 289/400\n",
            " - 0s - loss: 0.6611 - cosine_proximity: -5.0000e-01\n",
            "Epoch 290/400\n",
            " - 0s - loss: 0.6609 - cosine_proximity: -5.0000e-01\n",
            "Epoch 291/400\n",
            " - 0s - loss: 0.6606 - cosine_proximity: -5.0000e-01\n",
            "Epoch 292/400\n",
            " - 0s - loss: 0.6603 - cosine_proximity: -5.0000e-01\n",
            "Epoch 293/400\n",
            " - 0s - loss: 0.6600 - cosine_proximity: -5.0000e-01\n",
            "Epoch 294/400\n",
            " - 0s - loss: 0.6597 - cosine_proximity: -5.0000e-01\n",
            "Epoch 295/400\n",
            " - 0s - loss: 0.6594 - cosine_proximity: -5.0000e-01\n",
            "Epoch 296/400\n",
            " - 0s - loss: 0.6591 - cosine_proximity: -5.0000e-01\n",
            "Epoch 297/400\n",
            " - 0s - loss: 0.6588 - cosine_proximity: -5.0000e-01\n",
            "Epoch 298/400\n",
            " - 0s - loss: 0.6585 - cosine_proximity: -5.0000e-01\n",
            "Epoch 299/400\n",
            " - 0s - loss: 0.6582 - cosine_proximity: -5.0000e-01\n",
            "Epoch 300/400\n",
            " - 0s - loss: 0.6580 - cosine_proximity: -5.0000e-01\n",
            "Epoch 301/400\n",
            " - 0s - loss: 0.6577 - cosine_proximity: -5.0000e-01\n",
            "Epoch 302/400\n",
            " - 0s - loss: 0.6574 - cosine_proximity: -5.0000e-01\n",
            "Epoch 303/400\n",
            " - 0s - loss: 0.6571 - cosine_proximity: -5.0000e-01\n",
            "Epoch 304/400\n",
            " - 0s - loss: 0.6568 - cosine_proximity: -5.0000e-01\n",
            "Epoch 305/400\n",
            " - 0s - loss: 0.6565 - cosine_proximity: -5.0000e-01\n",
            "Epoch 306/400\n",
            " - 0s - loss: 0.6562 - cosine_proximity: -5.0000e-01\n",
            "Epoch 307/400\n",
            " - 0s - loss: 0.6559 - cosine_proximity: -5.0000e-01\n",
            "Epoch 308/400\n",
            " - 0s - loss: 0.6556 - cosine_proximity: -5.0000e-01\n",
            "Epoch 309/400\n",
            " - 0s - loss: 0.6553 - cosine_proximity: -5.0000e-01\n",
            "Epoch 310/400\n",
            " - 0s - loss: 0.6550 - cosine_proximity: -5.0000e-01\n",
            "Epoch 311/400\n",
            " - 0s - loss: 0.6547 - cosine_proximity: -5.0000e-01\n",
            "Epoch 312/400\n",
            " - 0s - loss: 0.6544 - cosine_proximity: -5.0000e-01\n",
            "Epoch 313/400\n",
            " - 0s - loss: 0.6541 - cosine_proximity: -5.0000e-01\n",
            "Epoch 314/400\n",
            " - 0s - loss: 0.6538 - cosine_proximity: -5.0000e-01\n",
            "Epoch 315/400\n",
            " - 0s - loss: 0.6536 - cosine_proximity: -5.0000e-01\n",
            "Epoch 316/400\n",
            " - 0s - loss: 0.6533 - cosine_proximity: -5.0000e-01\n",
            "Epoch 317/400\n",
            " - 0s - loss: 0.6530 - cosine_proximity: -5.0000e-01\n",
            "Epoch 318/400\n",
            " - 0s - loss: 0.6527 - cosine_proximity: -5.0000e-01\n",
            "Epoch 319/400\n",
            " - 0s - loss: 0.6524 - cosine_proximity: -5.0000e-01\n",
            "Epoch 320/400\n",
            " - 0s - loss: 0.6521 - cosine_proximity: -5.0000e-01\n",
            "Epoch 321/400\n",
            " - 0s - loss: 0.6518 - cosine_proximity: -5.0000e-01\n",
            "Epoch 322/400\n",
            " - 0s - loss: 0.6515 - cosine_proximity: -5.0000e-01\n",
            "Epoch 323/400\n",
            " - 0s - loss: 0.6512 - cosine_proximity: -5.0000e-01\n",
            "Epoch 324/400\n",
            " - 0s - loss: 0.6509 - cosine_proximity: -5.0000e-01\n",
            "Epoch 325/400\n",
            " - 0s - loss: 0.6506 - cosine_proximity: -5.0000e-01\n",
            "Epoch 326/400\n",
            " - 0s - loss: 0.6503 - cosine_proximity: -5.0000e-01\n",
            "Epoch 327/400\n",
            " - 0s - loss: 0.6500 - cosine_proximity: -5.0000e-01\n",
            "Epoch 328/400\n",
            " - 0s - loss: 0.6497 - cosine_proximity: -5.0000e-01\n",
            "Epoch 329/400\n",
            " - 0s - loss: 0.6494 - cosine_proximity: -5.0000e-01\n",
            "Epoch 330/400\n",
            " - 0s - loss: 0.6491 - cosine_proximity: -5.0000e-01\n",
            "Epoch 331/400\n",
            " - 0s - loss: 0.6488 - cosine_proximity: -5.0000e-01\n",
            "Epoch 332/400\n",
            " - 0s - loss: 0.6485 - cosine_proximity: -5.0000e-01\n",
            "Epoch 333/400\n",
            " - 0s - loss: 0.6482 - cosine_proximity: -5.0000e-01\n",
            "Epoch 334/400\n",
            " - 0s - loss: 0.6479 - cosine_proximity: -5.0000e-01\n",
            "Epoch 335/400\n",
            " - 0s - loss: 0.6476 - cosine_proximity: -5.0000e-01\n",
            "Epoch 336/400\n",
            " - 0s - loss: 0.6473 - cosine_proximity: -5.0000e-01\n",
            "Epoch 337/400\n",
            " - 0s - loss: 0.6470 - cosine_proximity: -5.0000e-01\n",
            "Epoch 338/400\n",
            " - 0s - loss: 0.6467 - cosine_proximity: -5.0000e-01\n",
            "Epoch 339/400\n",
            " - 0s - loss: 0.6464 - cosine_proximity: -5.0000e-01\n",
            "Epoch 340/400\n",
            " - 0s - loss: 0.6461 - cosine_proximity: -5.0000e-01\n",
            "Epoch 341/400\n",
            " - 0s - loss: 0.6458 - cosine_proximity: -5.0000e-01\n",
            "Epoch 342/400\n",
            " - 0s - loss: 0.6455 - cosine_proximity: -5.0000e-01\n",
            "Epoch 343/400\n",
            " - 0s - loss: 0.6452 - cosine_proximity: -5.0000e-01\n",
            "Epoch 344/400\n",
            " - 0s - loss: 0.6449 - cosine_proximity: -5.0000e-01\n",
            "Epoch 345/400\n",
            " - 0s - loss: 0.6446 - cosine_proximity: -5.0000e-01\n",
            "Epoch 346/400\n",
            " - 0s - loss: 0.6443 - cosine_proximity: -5.0000e-01\n",
            "Epoch 347/400\n",
            " - 0s - loss: 0.6440 - cosine_proximity: -5.0000e-01\n",
            "Epoch 348/400\n",
            " - 0s - loss: 0.6437 - cosine_proximity: -5.0000e-01\n",
            "Epoch 349/400\n",
            " - 0s - loss: 0.6434 - cosine_proximity: -5.0000e-01\n",
            "Epoch 350/400\n",
            " - 0s - loss: 0.6431 - cosine_proximity: -5.0000e-01\n",
            "Epoch 351/400\n",
            " - 0s - loss: 0.6428 - cosine_proximity: -5.0000e-01\n",
            "Epoch 352/400\n",
            " - 0s - loss: 0.6425 - cosine_proximity: -5.0000e-01\n",
            "Epoch 353/400\n",
            " - 0s - loss: 0.6422 - cosine_proximity: -5.0000e-01\n",
            "Epoch 354/400\n",
            " - 0s - loss: 0.6419 - cosine_proximity: -5.0000e-01\n",
            "Epoch 355/400\n",
            " - 0s - loss: 0.6416 - cosine_proximity: -5.0000e-01\n",
            "Epoch 356/400\n",
            " - 0s - loss: 0.6413 - cosine_proximity: -5.0000e-01\n",
            "Epoch 357/400\n",
            " - 0s - loss: 0.6410 - cosine_proximity: -5.0000e-01\n",
            "Epoch 358/400\n",
            " - 0s - loss: 0.6407 - cosine_proximity: -5.0000e-01\n",
            "Epoch 359/400\n",
            " - 0s - loss: 0.6404 - cosine_proximity: -5.0000e-01\n",
            "Epoch 360/400\n",
            " - 0s - loss: 0.6401 - cosine_proximity: -5.0000e-01\n",
            "Epoch 361/400\n",
            " - 0s - loss: 0.6398 - cosine_proximity: -5.0000e-01\n",
            "Epoch 362/400\n",
            " - 0s - loss: 0.6394 - cosine_proximity: -5.0000e-01\n",
            "Epoch 363/400\n",
            " - 0s - loss: 0.6391 - cosine_proximity: -5.0000e-01\n",
            "Epoch 364/400\n",
            " - 0s - loss: 0.6388 - cosine_proximity: -5.0000e-01\n",
            "Epoch 365/400\n",
            " - 0s - loss: 0.6385 - cosine_proximity: -5.0000e-01\n",
            "Epoch 366/400\n",
            " - 0s - loss: 0.6382 - cosine_proximity: -5.0000e-01\n",
            "Epoch 367/400\n",
            " - 0s - loss: 0.6379 - cosine_proximity: -5.0000e-01\n",
            "Epoch 368/400\n",
            " - 0s - loss: 0.6376 - cosine_proximity: -5.0000e-01\n",
            "Epoch 369/400\n",
            " - 0s - loss: 0.6373 - cosine_proximity: -5.0000e-01\n",
            "Epoch 370/400\n",
            " - 0s - loss: 0.6370 - cosine_proximity: -5.0000e-01\n",
            "Epoch 371/400\n",
            " - 0s - loss: 0.6367 - cosine_proximity: -5.0000e-01\n",
            "Epoch 372/400\n",
            " - 0s - loss: 0.6364 - cosine_proximity: -5.0000e-01\n",
            "Epoch 373/400\n",
            " - 0s - loss: 0.6361 - cosine_proximity: -5.0000e-01\n",
            "Epoch 374/400\n",
            " - 0s - loss: 0.6358 - cosine_proximity: -5.0000e-01\n",
            "Epoch 375/400\n",
            " - 0s - loss: 0.6355 - cosine_proximity: -5.0000e-01\n",
            "Epoch 376/400\n",
            " - 0s - loss: 0.6351 - cosine_proximity: -5.0000e-01\n",
            "Epoch 377/400\n",
            " - 0s - loss: 0.6348 - cosine_proximity: -5.0000e-01\n",
            "Epoch 378/400\n",
            " - 0s - loss: 0.6345 - cosine_proximity: -5.0000e-01\n",
            "Epoch 379/400\n",
            " - 0s - loss: 0.6342 - cosine_proximity: -5.0000e-01\n",
            "Epoch 380/400\n",
            " - 0s - loss: 0.6339 - cosine_proximity: -5.0000e-01\n",
            "Epoch 381/400\n",
            " - 0s - loss: 0.6336 - cosine_proximity: -5.0000e-01\n",
            "Epoch 382/400\n",
            " - 0s - loss: 0.6333 - cosine_proximity: -5.0000e-01\n",
            "Epoch 383/400\n",
            " - 0s - loss: 0.6330 - cosine_proximity: -5.0000e-01\n",
            "Epoch 384/400\n",
            " - 0s - loss: 0.6327 - cosine_proximity: -5.0000e-01\n",
            "Epoch 385/400\n",
            " - 0s - loss: 0.6324 - cosine_proximity: -5.0000e-01\n",
            "Epoch 386/400\n",
            " - 0s - loss: 0.6320 - cosine_proximity: -5.0000e-01\n",
            "Epoch 387/400\n",
            " - 0s - loss: 0.6317 - cosine_proximity: -5.0000e-01\n",
            "Epoch 388/400\n",
            " - 0s - loss: 0.6314 - cosine_proximity: -5.0000e-01\n",
            "Epoch 389/400\n",
            " - 0s - loss: 0.6311 - cosine_proximity: -5.0000e-01\n",
            "Epoch 390/400\n",
            " - 0s - loss: 0.6308 - cosine_proximity: -5.0000e-01\n",
            "Epoch 391/400\n",
            " - 0s - loss: 0.6305 - cosine_proximity: -5.0000e-01\n",
            "Epoch 392/400\n",
            " - 0s - loss: 0.6302 - cosine_proximity: -5.0000e-01\n",
            "Epoch 393/400\n",
            " - 0s - loss: 0.6299 - cosine_proximity: -5.0000e-01\n",
            "Epoch 394/400\n",
            " - 0s - loss: 0.6295 - cosine_proximity: -5.0000e-01\n",
            "Epoch 395/400\n",
            " - 0s - loss: 0.6292 - cosine_proximity: -5.0000e-01\n",
            "Epoch 396/400\n",
            " - 0s - loss: 0.6289 - cosine_proximity: -5.0000e-01\n",
            "Epoch 397/400\n",
            " - 0s - loss: 0.6286 - cosine_proximity: -5.0000e-01\n",
            "Epoch 398/400\n",
            " - 0s - loss: 0.6283 - cosine_proximity: -5.0000e-01\n",
            "Epoch 399/400\n",
            " - 0s - loss: 0.6280 - cosine_proximity: -5.0000e-01\n",
            "Epoch 400/400\n",
            " - 0s - loss: 0.6277 - cosine_proximity: -5.0000e-01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Vp_MB0QVEzU",
        "colab_type": "text"
      },
      "source": [
        "#Thank you for completing the notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTYTpK4PFF1A",
        "colab_type": "text"
      },
      "source": [
        "*ACCURACY SCORES*\n",
        "\n",
        "**Accuracy-**\n",
        "\n",
        "Test loss: 0.10376196658944027\n",
        "\n",
        "\n",
        "Test accuracy: 0.9757\n",
        "\n",
        "\n",
        "**binary_accuracy-**\n",
        "\n",
        "Test loss: 0.15646206490577766\n",
        "\n",
        "\n",
        "Test accuracy: 0.9955399974822998\n",
        "\n",
        "\n",
        "**categorical_accuracy-**\n",
        "\n",
        "Test loss: 0.14195446051103405\n",
        "\n",
        "\n",
        "Test accuracy: 0.9816\n",
        "\n",
        "\n",
        "**top_k_categorical_accuracy-**\n",
        "\n",
        "Test loss: 0.15224556388646485\n",
        "\n",
        "\n",
        "Test accuracy: 0.9999\n",
        "\n",
        "\n",
        "**sparse_categorical_accuracy-**\n",
        "\n",
        "loss: 0.4375 \n",
        "\n",
        "\n",
        "sparse_categorical_accuracy: 0.5000\n",
        "\n",
        "\n",
        "**sparse_top_k_categorical_accuracy-**\n",
        "\n",
        "loss: 0.7547 \n",
        "\n",
        "\n",
        "sparse_top_k_categorical_accuracy: 0.5000\n",
        "\n",
        "\n",
        "**cosine_proximity-**\n",
        "\n",
        "loss: 0.7574 \n",
        "\n",
        "\n",
        "cosine_proximity: -5.0000e-01"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXtv1hZ7KTzZ",
        "colab_type": "text"
      },
      "source": [
        "The best metric among all is **top_k_categorical_accuracy** which gives almost an accuracy of 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LatctACmMT9Y",
        "colab_type": "code",
        "outputId": "baee69f7-caee-4c7d-e266-b773057eb9da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        }
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "#import dataset\n",
        "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
        "\n",
        "#change shape from image to vector\n",
        "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
        "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
        "\n",
        "#preprocess\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "\n",
        "#change labels from numeric to one hot encoded\n",
        "Y_train = to_categorical(Y_train, 10)\n",
        "Y_test =  to_categorical(Y_test, 10)\n",
        "\n",
        "#Model building\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, input_shape=(3072, )))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# Compile model using above optimizer\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['top_k_categorical_accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, Y_test))\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "50000/50000 [==============================] - 2s 50us/step - loss: 2.4006 - top_k_categorical_accuracy: 0.7490 - val_loss: 1.8313 - val_top_k_categorical_accuracy: 0.8438\n",
            "Epoch 2/10\n",
            "50000/50000 [==============================] - 2s 41us/step - loss: 1.8006 - top_k_categorical_accuracy: 0.8496 - val_loss: 1.7774 - val_top_k_categorical_accuracy: 0.8473\n",
            "Epoch 3/10\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.6997 - top_k_categorical_accuracy: 0.8728 - val_loss: 1.6803 - val_top_k_categorical_accuracy: 0.8772\n",
            "Epoch 4/10\n",
            "50000/50000 [==============================] - 2s 41us/step - loss: 1.6284 - top_k_categorical_accuracy: 0.8870 - val_loss: 1.5789 - val_top_k_categorical_accuracy: 0.8959\n",
            "Epoch 5/10\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.5710 - top_k_categorical_accuracy: 0.8996 - val_loss: 1.6857 - val_top_k_categorical_accuracy: 0.8751\n",
            "Epoch 6/10\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.5298 - top_k_categorical_accuracy: 0.9055 - val_loss: 1.7040 - val_top_k_categorical_accuracy: 0.8841\n",
            "Epoch 7/10\n",
            "50000/50000 [==============================] - 2s 41us/step - loss: 1.4924 - top_k_categorical_accuracy: 0.9120 - val_loss: 1.6079 - val_top_k_categorical_accuracy: 0.8926\n",
            "Epoch 8/10\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 1.4643 - top_k_categorical_accuracy: 0.9164 - val_loss: 1.5450 - val_top_k_categorical_accuracy: 0.9081\n",
            "Epoch 9/10\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 1.4368 - top_k_categorical_accuracy: 0.9218 - val_loss: 1.4648 - val_top_k_categorical_accuracy: 0.9169\n",
            "Epoch 10/10\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.4147 - top_k_categorical_accuracy: 0.9217 - val_loss: 1.4539 - val_top_k_categorical_accuracy: 0.9237\n",
            "Test loss: 1.4539491662979125\n",
            "Test accuracy: 0.9237\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eZxoUOWNTpK",
        "colab_type": "text"
      },
      "source": [
        "**CIFAR 10**\n",
        "\n",
        "Test loss: 1.4908046955108643\n",
        "\n",
        "\n",
        "Test accuracy: 0.914"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkNHWHHvNIdL",
        "colab_type": "code",
        "outputId": "8626d98b-6610-4387-c1f7-509c8e27271c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        }
      },
      "source": [
        "from keras.datasets import cifar100\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "#import dataset\n",
        "(X_train, Y_train), (X_test, Y_test) = cifar100.load_data()\n",
        "\n",
        "#change shape from image to vector\n",
        "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
        "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
        "\n",
        "#preprocess\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "\n",
        "#change labels from numeric to one hot encoded\n",
        "Y_train = to_categorical(Y_train, 100)\n",
        "Y_test =  to_categorical(Y_test, 100)\n",
        "\n",
        "#Model building\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, input_shape=(3072, )))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(100))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "from keras import optimizers\n",
        "adamax=keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "# Compile model using above optimizer\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['top_k_categorical_accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, Y_test))\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 4s 0us/step\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "50000/50000 [==============================] - 3s 52us/step - loss: 4.2765 - top_k_categorical_accuracy: 0.2107 - val_loss: 3.8325 - val_top_k_categorical_accuracy: 0.3267\n",
            "Epoch 2/10\n",
            "50000/50000 [==============================] - 2s 41us/step - loss: 3.7775 - top_k_categorical_accuracy: 0.3411 - val_loss: 3.7126 - val_top_k_categorical_accuracy: 0.3562\n",
            "Epoch 3/10\n",
            "50000/50000 [==============================] - 2s 41us/step - loss: 3.5882 - top_k_categorical_accuracy: 0.3948 - val_loss: 3.7838 - val_top_k_categorical_accuracy: 0.3731\n",
            "Epoch 4/10\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 3.4546 - top_k_categorical_accuracy: 0.4326 - val_loss: 3.5597 - val_top_k_categorical_accuracy: 0.4101\n",
            "Epoch 5/10\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 3.3407 - top_k_categorical_accuracy: 0.4653 - val_loss: 3.5403 - val_top_k_categorical_accuracy: 0.4228\n",
            "Epoch 6/10\n",
            "50000/50000 [==============================] - 2s 41us/step - loss: 3.2460 - top_k_categorical_accuracy: 0.4896 - val_loss: 3.3152 - val_top_k_categorical_accuracy: 0.4804\n",
            "Epoch 7/10\n",
            "50000/50000 [==============================] - 2s 41us/step - loss: 3.1607 - top_k_categorical_accuracy: 0.5105 - val_loss: 3.4573 - val_top_k_categorical_accuracy: 0.4566\n",
            "Epoch 8/10\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 3.0983 - top_k_categorical_accuracy: 0.5265 - val_loss: 3.4149 - val_top_k_categorical_accuracy: 0.4634\n",
            "Epoch 9/10\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 3.0318 - top_k_categorical_accuracy: 0.5441 - val_loss: 3.4113 - val_top_k_categorical_accuracy: 0.4847\n",
            "Epoch 10/10\n",
            "50000/50000 [==============================] - 2s 41us/step - loss: 2.9680 - top_k_categorical_accuracy: 0.5588 - val_loss: 3.4234 - val_top_k_categorical_accuracy: 0.4716\n",
            "Test loss: 3.423366353607178\n",
            "Test accuracy: 0.4716\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-5z-Rk_NjXe",
        "colab_type": "text"
      },
      "source": [
        "**CIFAR 100**\n",
        "\n",
        "Test loss: 3.393477967834473\n",
        "\n",
        "\n",
        "Test accuracy: 0.483"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbtFF2pVMg1F",
        "colab_type": "code",
        "outputId": "8b566245-0770-48e8-d507-15c6af7d5b50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        }
      },
      "source": [
        "import keras\n",
        "from keras import models\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "\n",
        "NUM_ROWS = 28\n",
        "NUM_COLS = 28\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10\n",
        "\n",
        "# Load data\n",
        "(X_train, Y_train), (X_test, Y_test) = fashion_mnist.load_data()\n",
        "\n",
        "\n",
        "\n",
        "# Reshape data\n",
        "X_train = X_train.reshape((X_train.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.reshape((X_test.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "# Categorically encode labels\n",
        "Y_train = to_categorical(Y_train, NUM_CLASSES)\n",
        "Y_test = to_categorical(Y_test, NUM_CLASSES)\n",
        "\n",
        "\n",
        "# Build neural network\n",
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile model using above optimizer\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['top_k_categorical_accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, Y_test))\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 4us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 2s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 1s 0us/step\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 0.5421 - top_k_categorical_accuracy: 0.9927 - val_loss: 0.4280 - val_top_k_categorical_accuracy: 0.9968\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 0.3764 - top_k_categorical_accuracy: 0.9977 - val_loss: 0.4121 - val_top_k_categorical_accuracy: 0.9983\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.3355 - top_k_categorical_accuracy: 0.9983 - val_loss: 0.3812 - val_top_k_categorical_accuracy: 0.9968\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.3102 - top_k_categorical_accuracy: 0.9986 - val_loss: 0.3425 - val_top_k_categorical_accuracy: 0.9975\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.2929 - top_k_categorical_accuracy: 0.9990 - val_loss: 0.3883 - val_top_k_categorical_accuracy: 0.9979\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.2792 - top_k_categorical_accuracy: 0.9992 - val_loss: 0.3508 - val_top_k_categorical_accuracy: 0.9975\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.2665 - top_k_categorical_accuracy: 0.9991 - val_loss: 0.3483 - val_top_k_categorical_accuracy: 0.9980\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.2563 - top_k_categorical_accuracy: 0.9994 - val_loss: 0.4254 - val_top_k_categorical_accuracy: 0.9975\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 0.2469 - top_k_categorical_accuracy: 0.9994 - val_loss: 0.3535 - val_top_k_categorical_accuracy: 0.9980\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.2388 - top_k_categorical_accuracy: 0.9995 - val_loss: 0.3850 - val_top_k_categorical_accuracy: 0.9977\n",
            "Test loss: 0.38502425739765167\n",
            "Test accuracy: 0.9977\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XT_Hk41eNa3K",
        "colab_type": "text"
      },
      "source": [
        "**FASHION_MNIST**\n",
        "\n",
        "Test loss: 0.34572943717837334\n",
        "\n",
        "\n",
        "Test accuracy: 0.9981"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXoHL-Hdez8I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}